<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Aaron R. Caldwell" />

<meta name="date" content="2026-01-30" />

<title>Robust TOST Procedures</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Robust TOST Procedures</h1>
<h4 class="author">Aaron R. Caldwell</h4>
<h4 class="date">2026-01-30</h4>


<div id="TOC">
<ul>
<li><a href="#introduction-to-robust-tost-methods" id="toc-introduction-to-robust-tost-methods">Introduction to Robust TOST
Methods</a>
<ul>
<li><a href="#when-to-use-robust-tost-methods" id="toc-when-to-use-robust-tost-methods">When to Use Robust TOST
Methods</a></li>
</ul></li>
<li><a href="#wilcoxon-mann-whitney-tost" id="toc-wilcoxon-mann-whitney-tost">Wilcoxon-Mann-Whitney TOST</a>
<ul>
<li><a href="#why-wmw-tests-can-be-misleading" id="toc-why-wmw-tests-can-be-misleading">Why WMW Tests Can Be
Misleading</a>
<ul>
<li><a href="#what-wmw-actually-tests" id="toc-what-wmw-actually-tests">What WMW actually tests</a></li>
<li><a href="#counterexamples" id="toc-counterexamples">Counterexamples</a></li>
<li><a href="#the-problem-for-equivalence-testing" id="toc-the-problem-for-equivalence-testing">The problem for equivalence
testing</a></li>
<li><a href="#what-to-use-instead" id="toc-what-to-use-instead">What to
use instead</a></li>
</ul></li>
<li><a href="#key-features-and-usage" id="toc-key-features-and-usage">Key Features and Usage</a>
<ul>
<li><a href="#understanding-the-equivalence-bounds-eqb" id="toc-understanding-the-equivalence-bounds-eqb">Understanding the
Equivalence Bounds (<code>eqb</code>)</a></li>
<li><a href="#interpreting-the-results" id="toc-interpreting-the-results">Interpreting the Results</a></li>
</ul></li>
<li><a href="#standardized-effect-sizes" id="toc-standardized-effect-sizes">Standardized Effect Sizes</a></li>
</ul></li>
<li><a href="#brunner-munzel-test" id="toc-brunner-munzel-test">Brunner-Munzel Test</a>
<ul>
<li><a href="#overview-and-advantages" id="toc-overview-and-advantages">Overview and Advantages</a></li>
<li><a href="#basics-of-the-calculative-approach" id="toc-basics-of-the-calculative-approach">Basics of the Calculative
Approach</a></li>
<li><a href="#test-methods" id="toc-test-methods">Test Methods</a></li>
<li><a href="#examples" id="toc-examples">Examples</a>
<ul>
<li><a href="#basic-two-sample-test" id="toc-basic-two-sample-test">Basic Two-Sample Test</a></li>
<li><a href="#logit-transformation-for-range-preserving-cis" id="toc-logit-transformation-for-range-preserving-cis">Logit
Transformation for Range-Preserving CIs</a></li>
<li><a href="#equivalence-testing" id="toc-equivalence-testing">Equivalence Testing</a></li>
<li><a href="#minimal-effect-testing" id="toc-minimal-effect-testing">Minimal Effect Testing</a></li>
<li><a href="#paired-samples" id="toc-paired-samples">Paired
Samples</a></li>
<li><a href="#testing-against-a-non-standard-null" id="toc-testing-against-a-non-standard-null">Testing Against a
Non-Standard Null</a></li>
</ul></li>
<li><a href="#interpreting-brunner-munzel-results" id="toc-interpreting-brunner-munzel-results">Interpreting Brunner-Munzel
Results</a></li>
<li><a href="#choosing-the-right-test-method" id="toc-choosing-the-right-test-method">Choosing the Right Test
Method</a></li>
<li><a href="#non-inferiority-testing" id="toc-non-inferiority-testing">Non-Inferiority Testing</a></li>
</ul></li>
<li><a href="#hodges-lehmann-estimator-and-test" id="toc-hodges-lehmann-estimator-and-test">Hodges-Lehmann Estimator and
Test</a>
<ul>
<li><a href="#why-use-the-hodges-lehmann-estimator" id="toc-why-use-the-hodges-lehmann-estimator">Why Use the Hodges-Lehmann
Estimator?</a></li>
<li><a href="#estimators" id="toc-estimators">Estimators</a></li>
<li><a href="#test-methods-1" id="toc-test-methods-1">Test
Methods</a></li>
<li><a href="#examples-1" id="toc-examples-1">Examples</a>
<ul>
<li><a href="#basic-two-sample-test-1" id="toc-basic-two-sample-test-1">Basic Two-Sample Test</a></li>
<li><a href="#permutation-based-test" id="toc-permutation-based-test">Permutation-Based Test</a></li>
<li><a href="#equivalence-testing-1" id="toc-equivalence-testing-1">Equivalence Testing</a></li>
<li><a href="#paired-samples-1" id="toc-paired-samples-1">Paired
Samples</a></li>
<li><a href="#minimal-effect-testing-1" id="toc-minimal-effect-testing-1">Minimal Effect Testing</a></li>
</ul></li>
<li><a href="#choosing-the-right-approach" id="toc-choosing-the-right-approach">Choosing the Right
Approach</a></li>
</ul></li>
<li><a href="#resampling-methods-bootstrapping-and-permutation" id="toc-resampling-methods-bootstrapping-and-permutation">Resampling
Methods: Bootstrapping and Permutation</a>
<ul>
<li><a href="#conceptual-overview" id="toc-conceptual-overview">Conceptual Overview</a></li>
<li><a href="#when-to-use-each-method" id="toc-when-to-use-each-method">When to Use Each Method</a></li>
</ul></li>
<li><a href="#permutation-t-test" id="toc-permutation-t-test">Permutation t-test</a>
<ul>
<li><a href="#permutation-procedure" id="toc-permutation-procedure">Permutation Procedure</a></li>
<li><a href="#two-sample-permutation-algorithm" id="toc-two-sample-permutation-algorithm">Two-Sample Permutation
Algorithm</a>
<ul>
<li><a href="#welch-variant-var.equal-false" id="toc-welch-variant-var.equal-false">Welch Variant (var.equal =
FALSE)</a></li>
<li><a href="#pooled-variance-variant-var.equal-true" id="toc-pooled-variance-variant-var.equal-true">Pooled Variance Variant
(var.equal = TRUE)</a></li>
<li><a href="#yuen-variant-tr-0" id="toc-yuen-variant-tr-0">Yuen Variant
(tr &gt; 0)</a></li>
</ul></li>
<li><a href="#studentized-permutation-the-perm_se-argument" id="toc-studentized-permutation-the-perm_se-argument">Studentized
Permutation: The <code>perm_se</code> Argument</a></li>
<li><a href="#combining-permutation-with-trimmed-means" id="toc-combining-permutation-with-trimmed-means">Combining Permutation
with Trimmed Means</a></li>
<li><a href="#example-basic-permutation-test" id="toc-example-basic-permutation-test">Example: Basic Permutation
Test</a></li>
<li><a href="#example-permutation-test-with-trimming" id="toc-example-permutation-test-with-trimming">Example: Permutation
Test with Trimming</a></li>
<li><a href="#example-equivalence-testing-with-permutation" id="toc-example-equivalence-testing-with-permutation">Example:
Equivalence Testing with Permutation</a></li>
<li><a href="#exact-vs.-monte-carlo-permutations" id="toc-exact-vs.-monte-carlo-permutations">Exact vs. Monte Carlo
Permutations</a></li>
</ul></li>
<li><a href="#bootstrap-t-test" id="toc-bootstrap-t-test">Bootstrap
t-test</a>
<ul>
<li><a href="#advantages-of-bootstrapping" id="toc-advantages-of-bootstrapping">Advantages of
Bootstrapping</a></li>
<li><a href="#bootstrap-algorithm-two-sample-case" id="toc-bootstrap-algorithm-two-sample-case">Bootstrap Algorithm
(Two-Sample Case)</a></li>
<li><a href="#choosing-the-number-of-bootstrap-replications" id="toc-choosing-the-number-of-bootstrap-replications">Choosing the
Number of Bootstrap Replications</a></li>
<li><a href="#example" id="toc-example">Example</a>
<ul>
<li><a href="#interpreting-bootstrap-tost-results" id="toc-interpreting-bootstrap-tost-results">Interpreting Bootstrap TOST
Results</a></li>
</ul></li>
</ul></li>
<li><a href="#comparing-bootstrap-and-permutation-approaches" id="toc-comparing-bootstrap-and-permutation-approaches">Comparing
Bootstrap and Permutation Approaches</a>
<ul>
<li><a href="#summary-choosing-between-methods" id="toc-summary-choosing-between-methods">Summary: Choosing Between
Methods</a></li>
</ul></li>
<li><a href="#ratio-of-difference-log-transformed" id="toc-ratio-of-difference-log-transformed">Ratio of Difference (Log
Transformed)</a>
<ul>
<li><a href="#why-use-the-natural-log-transformation" id="toc-why-use-the-natural-log-transformation">Why Use The Natural Log
Transformation?</a></li>
<li><a href="#applications-beyond-bioequivalence" id="toc-applications-beyond-bioequivalence">Applications Beyond
Bioequivalence</a></li>
<li><a href="#log_tost" id="toc-log_tost">log_TOST</a>
<ul>
<li><a href="#interpreting-the-means-ratio" id="toc-interpreting-the-means-ratio">Interpreting the Means
Ratio</a></li>
</ul></li>
<li><a href="#bootstrap-log" id="toc-bootstrap-log">Bootstrap +
Log</a></li>
</ul></li>
<li><a href="#standardized-effect-sizes-estimation-and-testing" id="toc-standardized-effect-sizes-estimation-and-testing">Standardized
Effect Sizes: Estimation and Testing</a>
<ul>
<li><a href="#available-effect-sizes" id="toc-available-effect-sizes">Available Effect Sizes</a>
<ul>
<li><a href="#rank-biserial-correlation" id="toc-rank-biserial-correlation">Rank-Biserial Correlation</a></li>
<li><a href="#concordance-probability" id="toc-concordance-probability">Concordance Probability</a></li>
<li><a href="#wmw-odds" id="toc-wmw-odds">WMW Odds</a></li>
<li><a href="#guidelines-for-selecting-effect-size-measures" id="toc-guidelines-for-selecting-effect-size-measures">Guidelines for
Selecting Effect Size Measures</a></li>
</ul></li>
<li><a href="#confidence-interval-methods" id="toc-confidence-interval-methods">Confidence Interval Methods</a>
<ul>
<li><a href="#fisher-z-transformation-legacy-method" id="toc-fisher-z-transformation-legacy-method">Fisher z-Transformation
(Legacy Method)</a></li>
</ul></li>
<li><a href="#effect-size-estimation" id="toc-effect-size-estimation">Effect Size Estimation</a>
<ul>
<li><a href="#choosing-between-bootstrap-ci-methods" id="toc-choosing-between-bootstrap-ci-methods">Choosing Between
Bootstrap CI Methods</a></li>
</ul></li>
<li><a href="#hypothesis-testing-with-ses_calc" id="toc-hypothesis-testing-with-ses_calc">Hypothesis Testing with
<code>ses_calc</code></a>
<ul>
<li><a href="#equivalence-testing-on-the-effect-size-scale" id="toc-equivalence-testing-on-the-effect-size-scale">Equivalence
Testing on the Effect Size Scale</a></li>
</ul></li>
<li><a href="#permutation-based-effect-size-testing-with-perm_ses_test" id="toc-permutation-based-effect-size-testing-with-perm_ses_test">Permutation-Based
Effect Size Testing with <code>perm_ses_test</code></a>
<ul>
<li><a href="#equivalence-testing-with-permutation" id="toc-equivalence-testing-with-permutation">Equivalence Testing with
Permutation</a></li>
<li><a href="#when-to-use-perm_ses_test-vs.-ses_calc" id="toc-when-to-use-perm_ses_test-vs.-ses_calc">When to Use
<code>perm_ses_test</code> vs. <code>ses_calc</code></a></li>
</ul></li>
</ul></li>
<li><a href="#summary-comparison-of-robust-tost-methods" id="toc-summary-comparison-of-robust-tost-methods">Summary Comparison of
Robust TOST Methods</a></li>
<li><a href="#conclusion" id="toc-conclusion">Conclusion</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<div id="introduction-to-robust-tost-methods" class="section level1">
<h1>Introduction to Robust TOST Methods</h1>
<p>The Two One-Sided Tests (TOST) procedure is a statistical approach
used to test for equivalence between groups or conditions. Unlike
traditional null hypothesis significance testing (NHST) which aims to
detect differences, TOST is designed to statistically demonstrate
similarity or equivalence within predefined bounds.</p>
<p>While the standard <code>t_TOST</code> function in TOSTER provides a
parametric approach to equivalence testing, it relies on assumptions of
normality and homogeneity of variance. In real-world data analysis,
these assumptions are often violated, necessitating more robust
alternatives. This vignette introduces several robust TOST methods
available in the TOSTER package that maintain their validity under a
wider range of data conditions.</p>
<div id="when-to-use-robust-tost-methods" class="section level2">
<h2>When to Use Robust TOST Methods</h2>
<p>Consider using the robust alternatives to <code>t_TOST</code>
when:</p>
<ul>
<li>Your data shows notable departures from normality (e.g., skewed
distributions, heavy tails)</li>
<li>Potential outliers are a concern</li>
<li>Sample sizes are small or unequal</li>
<li>You have concerns about violating the assumptions of parametric
tests</li>
<li>You want to confirm parametric test results with complementary
nonparametric approaches</li>
</ul>
<p>The following table provides a quick overview of the robust methods
covered in this vignette:</p>
<table>
<colgroup>
<col width="14%" />
<col width="18%" />
<col width="38%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Function</th>
<th>Key Characteristics</th>
<th>Best Used When</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Wilcoxon TOST</td>
<td><code>wilcox_TOST()</code></td>
<td>Rank-based, nonparametric</td>
<td>Ordinal data; see caveats below</td>
</tr>
<tr class="even">
<td>Brunner-Munzel</td>
<td><code>brunner_munzel()</code></td>
<td>Probability-based, robust to heteroscedasticity</td>
<td>Stochastic superiority is the effect of interest</td>
</tr>
<tr class="odd">
<td>Hodges-Lehmann</td>
<td><code>hodges_lehmann()</code></td>
<td>Robust location estimator, permutation or asymptotic</td>
<td>Robust location shift testing, outlier resistance</td>
</tr>
<tr class="even">
<td>Permutation t-test</td>
<td><code>perm_t_test()</code></td>
<td>Resampling without replacement, exact p-values possible</td>
<td>Small samples, mean differences, exact inference</td>
</tr>
<tr class="odd">
<td>Bootstrap TOST</td>
<td><code>boot_t_TOST()</code></td>
<td>Resampling with replacement, flexible</td>
<td>Moderate samples, mean differences, visualization</td>
</tr>
<tr class="even">
<td>Log-Transformed TOST</td>
<td><code>log_TOST()</code></td>
<td>Ratio-based, for multiplicative comparisons</td>
<td>Comparing relative differences (e.g., bioequivalence)</td>
</tr>
<tr class="odd">
<td>SES estimation/testing</td>
<td><code>ses_calc()</code> / <code>perm_ses_test()</code></td>
<td>Non-parametric effect sizes with optional hypothesis testing</td>
<td>Testing on the effect size scale directly</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="wilcoxon-mann-whitney-tost" class="section level1">
<h1>Wilcoxon-Mann-Whitney TOST</h1>
<p>The Wilcoxon group of tests (includes Mann-Whitney U-test) provide a
non-parametric test of differences between groups, or within samples,
based on ranks. With TOST, there are two separate tests of directional
location shift to determine if the location shift is within
(equivalence) or outside (minimal effect). The exact calculations can be
explored via the documentation of the <code>wilcox.test</code>
function.</p>
<div id="why-wmw-tests-can-be-misleading" class="section level2">
<h2>Why WMW Tests Can Be Misleading</h2>
<p>While the Wilcoxon-Mann-Whitney (WMW) tests are widely used as the
“non-parametric alternative” to the t-test, there are important reasons
to be cautious about their interpretation — particularly in the
equivalence testing context.</p>
<div id="what-wmw-actually-tests" class="section level3">
<h3>What WMW actually tests</h3>
<p>A common misconception is that the WMW test compares medians <span class="citation">(see Karch 2021; Divine et al. 2018)</span>.
<strong>Without additional assumptions</strong>, the WMW test is a test
of stochastic equality:</p>
<p><span class="math display">\[
H_0: p = \Pr(X &lt; Y) + \frac{1}{2}\Pr(X = Y) = 0.5
\]</span></p>
<p>where <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are randomly selected observations from
the two groups. This quantity <span class="math inline">\(\hat{p} = U /
(n_1 \cdot n_2)\)</span> (where <span class="math inline">\(U\)</span>
is the Mann-Whitney U statistic) has nothing directly to do with means,
medians, or even the shapes of the distributions. It is the only
interpretation that holds without additional assumptions.</p>
<p>Only under a <strong>location-shift assumption</strong> (the two
distributions have identical shapes, differing only in location) does
the WMW test become a test about the Hodges-Lehmann pseudomedian of
pairwise differences. And only if the distributions are additionally
<strong>symmetric</strong> can this be interpreted as a test of median
or mean differences.</p>
</div>
<div id="counterexamples" class="section level3">
<h3>Counterexamples</h3>
<p><span class="citation">Divine et al. (2018)</span> demonstrate
several scenarios that illustrate the disconnect between the WMW test
and medians:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Equal medians, significant WMW test:</strong> Both groups
can have the same median yet the WMW test rejects <span class="math inline">\(H_0\)</span> (<span class="math inline">\(p &lt;
0.001\)</span>), because the distributions differ in shape.</p></li>
<li><p><strong>Very different medians, non-significant WMW
test:</strong> Samples can have medians of 9 vs. 99, yet <span class="math inline">\(\hat{p} \approx 0.5\)</span> with <span class="math inline">\(p \approx 1.0\)</span>, because neither group
stochastically dominates the other.</p></li>
<li><p><strong>Significance in the wrong direction:</strong> The group
with the higher median can have <span class="math inline">\(\hat{p} &gt;
0.5\)</span>, meaning the WMW test suggests the <em>opposite</em>
direction from the median comparison.</p></li>
</ol>
</div>
<div id="the-problem-for-equivalence-testing" class="section level3">
<h3>The problem for equivalence testing</h3>
<p>This interpretive difficulty becomes even more pronounced in the
equivalence testing context. When we perform TOST with Wilcoxon tests
via <code>wilcox_TOST</code>, we are testing whether a location shift
parameter (the Hodges-Lehmann pseudomedian of pairwise differences)
falls within equivalence bounds. But the relationship between this
parameter and familiar quantities like means or medians depends on the
location-shift and symmetry assumptions. If these assumptions are
violated, the equivalence bounds may not correspond to the magnitude of
difference you intended to declare equivalent.</p>
</div>
<div id="what-to-use-instead" class="section level3">
<h3>What to use instead</h3>
<p><strong>For differences in means (or trimmed means):</strong> Use
<code>perm_t_test</code> or <code>boot_t_TOST</code>. These test
hypotheses directly about means while relaxing distributional
assumptions.</p>
<p><strong>For stochastic superiority:</strong> Use
<code>brunner_munzel</code>, which provides a clearer framework with an
interpretable effect size (the relative effect, <span class="math inline">\(\hat{p}\)</span>) and directly supports
equivalence and minimal effect testing.</p>
<p><strong>For robust location testing:</strong> Use
<code>hodges_lehmann</code>, which explicitly tests the Hodges-Lehmann
estimator with permutation or asymptotic inference and makes the
location-shift assumption transparent.</p>
<p><strong>For testing effect sizes directly:</strong> Use
<code>ses_calc</code> or <code>perm_ses_test</code> to estimate and test
non-parametric standardized effect sizes (rank-biserial correlation, WMW
odds, concordance) with proper hypothesis testing support.</p>
<p>The <code>wilcox_TOST</code> function remains available for
situations where rank-based tests are specifically desired, such as with
ordinal data or when consistency with prior analyses that used WMW tests
is needed.</p>
</div>
</div>
<div id="key-features-and-usage" class="section level2">
<h2>Key Features and Usage</h2>
<p>TOSTER’s version is the <code>wilcox_TOST</code> function. Overall,
this function operates extremely similar to the <code>t_TOST</code>
function. However, the standardized mean difference (SMD) is
<em>not</em> calculated. Instead the rank-biserial correlation is
calculated for <em>all</em> types of comparisons (e.g., two sample, one
sample, and paired samples). Also, there is no plotting capability at
this time for the output of this function.</p>
<p>The <code>wilcox_TOST</code> function is particularly useful
when:</p>
<ul>
<li>You’re working with ordinal data</li>
<li>You’re concerned about outliers influencing your results</li>
<li>You need a test that makes minimal assumptions about the underlying
distributions</li>
</ul>
<div id="understanding-the-equivalence-bounds-eqb" class="section level3">
<h3>Understanding the Equivalence Bounds (<code>eqb</code>)</h3>
<p>The equivalence bounds (<code>eqb</code>) are specified on the
<strong>raw scale</strong> of your data, just like the <code>mu</code>
argument in <code>stats::wilcox.test()</code>. This means
<code>eqb</code> represents actual differences in location (e.g.,
location shifts) in the original units of measurement, not standardized
effect sizes. Unlike <code>t_TOST</code>, where <code>eqb</code>
<em>can</em> be set in terms of standardized mean differences (e.g.,
Cohen’s d), in <code>wilcox_TOST</code>, you <em>must</em> define
<code>eqb</code> based on the scale of your data for
<code>wilcox_TOST</code>.</p>
<p><strong>The <code>eqb</code> and <code>ses</code> parameters are
completely independent:</strong></p>
<ul>
<li><code>eqb</code> sets the equivalence bounds on the raw data scale
for the statistical test</li>
<li><code>ses</code> only determines which <em>type</em> of standardized
effect size is calculated and reported (e.g., rank-biserial correlation,
concordance probability, or odds)</li>
<li>Changing <code>ses</code> does <strong>not</strong> change the
meaning or interpretation of <code>eqb</code></li>
</ul>
<p>As an example, we can use the sleep data to make a non-parametric
comparison of equivalence.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&#39;sleep&#39;</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(TOSTER)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>test1 <span class="ot">=</span> <span class="fu">wilcox_TOST</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>)</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="fu">print</span>(test1)</span></code></pre></div>
<pre><code>## 
## Wilcoxon rank sum test with continuity correction
## 
## The equivalence test was non-significant W = 20.000, p = 8.94e-01
## The null hypothesis test was non-significant W = 25.500, p = 6.93e-02
## NHST: don&#39;t reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##            Test Statistic p.value
## NHST                 25.5   0.069
## TOST Lower           34.0   0.894
## TOST Upper           20.0   0.013
## 
## Effect Sizes 
##                           Estimate               C.I. Conf. Level
## Median of Differences       -1.346       [-3.4, -0.1]         0.9
## Rank-Biserial Correlation   -0.490 [-0.7493, -0.1005]         0.9</code></pre>
</div>
<div id="interpreting-the-results" class="section level3">
<h3>Interpreting the Results</h3>
<p>When interpreting the output of <code>wilcox_TOST</code>, pay
attention to:</p>
<ol style="list-style-type: decimal">
<li>The p-values for both one-sided tests (<code>p1</code> and
<code>p2</code>)</li>
<li>The equivalence test p-value (<code>TOSTp</code>), which should be
&lt; alpha to claim equivalence</li>
<li>The rank-biserial correlation (<code>rb</code>) and its confidence
interval</li>
</ol>
<p>A statistically significant equivalence test (p &lt; alpha) indicates
that the observed effect is statistically within your specified
equivalence bounds. The rank-biserial correlation provides a measure of
effect size, with values ranging from -1 to 1:</p>
<ul>
<li>Values near 0 indicate negligible association</li>
<li>Values around ±0.3 indicate a small effect</li>
<li>Values around ±0.5 indicate a moderate effect</li>
<li>Values around ±0.7 or greater indicate a large effect</li>
</ul>
</div>
</div>
<div id="standardized-effect-sizes" class="section level2">
<h2>Standardized Effect Sizes</h2>
<p>The <code>wilcox_TOST</code> function reports a standardized effect
size (SES) alongside the equivalence test. By default, this is the
rank-biserial correlation, but you can select other effect sizes —
concordance probability, WMW odds, or WMW log-odds — via the
<code>ses</code> argument. Changing <code>ses</code> only affects which
effect size is reported; it does <strong>not</strong> change the
equivalence test itself.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Rank biserial</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="fu">wilcox_TOST</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>                      <span class="at">ses =</span> <span class="st">&quot;r&quot;</span>,</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>)</span></code></pre></div>
<pre><code>## 
## Wilcoxon rank sum test with continuity correction
## 
## The equivalence test was non-significant W = 20.000, p = 8.94e-01
## The null hypothesis test was non-significant W = 25.500, p = 6.93e-02
## NHST: don&#39;t reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##            Test Statistic p.value
## NHST                 25.5   0.069
## TOST Lower           34.0   0.894
## TOST Upper           20.0   0.013
## 
## Effect Sizes 
##                           Estimate               C.I. Conf. Level
## Median of Differences       -1.346       [-3.4, -0.1]         0.9
## Rank-Biserial Correlation   -0.490 [-0.7493, -0.1005]         0.9</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Odds</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="fu">wilcox_TOST</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>                      <span class="at">ses =</span> <span class="st">&quot;o&quot;</span>,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>)</span></code></pre></div>
<pre><code>## 
## Wilcoxon rank sum test with continuity correction
## 
## The equivalence test was non-significant W = 20.000, p = 8.94e-01
## The null hypothesis test was non-significant W = 25.500, p = 6.93e-02
## NHST: don&#39;t reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##            Test Statistic p.value
## NHST                 25.5   0.069
## TOST Lower           34.0   0.894
## TOST Upper           20.0   0.013
## 
## Effect Sizes 
##                       Estimate             C.I. Conf. Level
## Median of Differences  -1.3464     [-3.4, -0.1]         0.9
## WMW Odds                0.3423 [0.1433, 0.8173]         0.9</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Concordance</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="fu">wilcox_TOST</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>                      <span class="at">ses =</span> <span class="st">&quot;c&quot;</span>,</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>)</span></code></pre></div>
<pre><code>## 
## Wilcoxon rank sum test with continuity correction
## 
## The equivalence test was non-significant W = 20.000, p = 8.94e-01
## The null hypothesis test was non-significant W = 25.500, p = 6.93e-02
## NHST: don&#39;t reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##            Test Statistic p.value
## NHST                 25.5   0.069
## TOST Lower           34.0   0.894
## TOST Upper           20.0   0.013
## 
## Effect Sizes 
##                       Estimate             C.I. Conf. Level
## Median of Differences   -1.346     [-3.4, -0.1]         0.9
## Concordance              0.255 [0.1254, 0.4497]         0.9</code></pre>
<p>For details on how each effect size is calculated, the available
confidence interval methods, and how to perform hypothesis testing
directly on the effect size scale, see the <a href="#standardized-effect-sizes-estimation-and-testing">Standardized
Effect Sizes: Estimation and Testing</a> section later in this
vignette.</p>
</div>
</div>
<div id="brunner-munzel-test" class="section level1">
<h1>Brunner-Munzel Test</h1>
<p>As Karch (2021) explained, there are some reasons to dislike the
Wilcoxon-Mann-Whitney (WMW) family of tests as the non-parametric
alternative to the t-test. Regardless of the underlying statistical
arguments<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, it can be argued that the interpretation
of the WMW tests, especially when involving equivalence testing, is
difficult. Some may want a non-parametric alternative to the WMW test,
and the Brunner-Munzel test(s) may be a useful option.</p>
<div id="overview-and-advantages" class="section level2">
<h2>Overview and Advantages</h2>
<p>The Brunner-Munzel test <span class="citation">(Brunner and Munzel
2000; Neubert and Brunner 2007)</span> offers several advantages over
the Wilcoxon-Mann-Whitney tests:</p>
<ol style="list-style-type: decimal">
<li>It does not assume equal distributions (shapes) between groups</li>
<li>It is robust to heteroscedasticity (unequal variances)</li>
<li>It provides a more interpretable effect size measure (the “relative
effect”)</li>
<li>It maintains good statistical properties even with unequal sample
sizes</li>
</ol>
<p>The Brunner-Munzel test is based on calculating the “stochastic
superiority” <span class="citation">(Karch 2021)</span>, which is
usually referred to as the relative effect, based on the ranks of the
two groups being compared (X and Y). A Brunner-Munzel type test is then
a directional test of an effect, and answers a question akin to “what is
the probability that a randomly sampled value of X will be greater than
Y?”</p>
<p><span class="math display">\[
\hat p = P(X&gt;Y) + 0.5 \cdot P(X=Y)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(P(X&gt;Y)\)</span> is the probability
that a random value from X exceeds a random value from Y</li>
<li><span class="math inline">\(P(X=Y)\)</span> is the probability that
random values from X and Y are equal</li>
<li>The 0.5 factor means ties contribute half their weight to the
probability</li>
</ul>
<p>The relative effect <span class="math inline">\(\hat p\)</span> has
an intuitive interpretation:</p>
<ul>
<li><span class="math inline">\(\hat p = 0.5\)</span> indicates no
difference between groups (stochastic equality)</li>
<li><span class="math inline">\(\hat p &gt; 0.5\)</span> indicates
values in X tend to be greater than values in Y</li>
<li><span class="math inline">\(\hat p &lt; 0.5\)</span> indicates
values in X tend to be smaller than values in Y</li>
</ul>
</div>
<div id="basics-of-the-calculative-approach" class="section level2">
<h2>Basics of the Calculative Approach</h2>
<p>A studentized test statistic can be calculated as:</p>
<p><span class="math display">\[
t = \sqrt{N} \cdot \frac{\hat p - p_{null}}{s}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(N\)</span> is the total sample size</li>
<li><span class="math inline">\(\hat p\)</span> is the estimated
relative effect</li>
<li><span class="math inline">\(p_{null}\)</span> is the null hypothesis
value (typically 0.5)</li>
<li><span class="math inline">\(s\)</span> is the rank-based
Brunner-Munzel standard error</li>
</ul>
<p>The default null hypothesis <span class="math inline">\(p_{null}\)</span> is typically 0.5 (50%
probability of superiority is the default null), and <span class="math inline">\(s\)</span> refers to the rank-based Brunner-Munzel
standard error. The null can be modified, thereby allowing for
equivalence testing <em>directly based on the relative effect</em>.
Additionally, for paired samples the probability of superiority is based
on a <em>hypothesis of exchangeability</em> and is not based on the
difference scores<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p>For more details on the calculative approach, I suggest reading <span class="citation">Karch (2021)</span>. At small sample sizes, it is
recommended that the permutation version of the test
(<code>test_method = &quot;perm&quot;</code>) be used rather than the basic test
statistic approach.</p>
</div>
<div id="test-methods" class="section level2">
<h2>Test Methods</h2>
<p>The <code>brunner_munzel</code> function provides three test methods
via the <code>test_method</code> argument:</p>
<ul>
<li><p><strong>“t”</strong> (default): Uses a t-distribution
approximation with Satterthwaite-Welch degrees of freedom. This is
appropriate for moderate to large sample sizes (generally n ≥ 15 per
group).</p></li>
<li><p><strong>“logit”</strong>: Uses a logit transformation to produce
range-preserving confidence intervals that are guaranteed to stay within
[0, 1]. This method is recommended when the estimated relative effect is
close to 0 or 1.</p></li>
<li><p><strong>“perm”</strong>: A studentized permutation test following
<span class="citation">Neubert and Brunner (2007)</span>. This method is
highly recommended when sample sizes are small (&lt; 15 per group) as it
provides better control of Type I error rates in these
situations.</p></li>
</ul>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<div id="basic-two-sample-test" class="section level3">
<h3>Basic Two-Sample Test</h3>
<p>The interface for the function is similar to <code>t.test</code>. The
<code>brunner_munzel</code> function allows for standard hypothesis
tests (“two.sided”, “less”, “greater”) as well as equivalence and
minimal effect tests.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Default studentized test (t-approximation)</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>               <span class="at">data =</span> sleep)</span></code></pre></div>
<pre><code>## Sample size in at least one group is small. Permutation test (test_method = &#39;perm&#39;) is highly recommended.</code></pre>
<pre><code>## 
##  Two-sample Brunner-Munzel test
## 
## data:  extra by group
## t = -2.1447, df = 16.898, p-value = 0.04682
## alternative hypothesis: true relative effect is not equal to 0.5
## 95 percent confidence interval:
##  0.01387048 0.49612952
## sample estimates:
## P(1&gt;2) + .5*P(1=2) 
##              0.255</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># Permutation test (recommended for small samples)</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>               <span class="at">test_method =</span> <span class="st">&quot;perm&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Two-sample Brunner-Munzel Randomization test
## 
## data:  extra by group
## t-observed = -2.1447, N-permutations = 10000, p-value = 0.05519
## alternative hypothesis: true relative effect is not equal to 0.5
## 95 percent confidence interval:
##  0.009706182 0.512854076
## sample estimates:
## P(1&gt;2) + .5*P(1=2) 
##              0.255</code></pre>
</div>
<div id="logit-transformation-for-range-preserving-cis" class="section level3">
<h3>Logit Transformation for Range-Preserving CIs</h3>
<p>When the relative effect estimate is close to 0 or 1, the standard
confidence intervals may extend beyond the valid [0, 1] range. The logit
transformation method addresses this:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># Logit transformation for range-preserving CIs</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>               <span class="at">test_method =</span> <span class="st">&quot;logit&quot;</span>)</span></code></pre></div>
<pre><code>## Sample size in at least one group is small. Permutation test (test_method = &#39;perm&#39;) is highly recommended.</code></pre>
<pre><code>## 
##  Two-sample Brunner-Munzel test (logit)
## 
## data:  extra by group
## t = -1.7829, df = 16.898, p-value = 0.09257
## alternative hypothesis: true relative effect is not equal to 0.5
## 95 percent confidence interval:
##  0.08775255 0.54912824
## sample estimates:
## P(1&gt;2) + .5*P(1=2) 
##              0.255</code></pre>
</div>
<div id="equivalence-testing" class="section level3">
<h3>Equivalence Testing</h3>
<p>The <code>brunner_munzel</code> function directly supports
equivalence testing via the <code>alternative</code> argument. For
equivalence tests, you specify bounds for the relative effect using the
<code>mu</code> argument:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co"># Equivalence test: is the relative effect between 0.3 and 0.7?</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>               <span class="at">alternative =</span> <span class="st">&quot;equivalence&quot;</span>,</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>               <span class="at">mu =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>))</span></code></pre></div>
<pre><code>## Sample size in at least one group is small. Permutation test (test_method = &#39;perm&#39;) is highly recommended.</code></pre>
<pre><code>## 
##  Two-sample Brunner-Munzel test
## 
## data:  extra by group
## t = -0.39392, df = 16.898, p-value = 0.6507
## alternative hypothesis: equivalence
## null values:
## lower bound upper bound 
##         0.3         0.7 
## 90 percent confidence interval:
##  0.0562039 0.4537961
## sample estimates:
## P(1&gt;2) + .5*P(1=2) 
##              0.255</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="co"># Permutation-based equivalence test</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>               <span class="at">alternative =</span> <span class="st">&quot;equivalence&quot;</span>,</span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>               <span class="at">mu =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>),</span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>               <span class="at">test_method =</span> <span class="st">&quot;perm&quot;</span>)</span></code></pre></div>
<pre><code>## NOTE: Permutation-based TOST for equivalence/minimal.effect testing.</code></pre>
<pre><code>## 
##  Two-sample Brunner-Munzel Randomization test
## 
## data:  extra by group
## t-observed = -0.39392, N-permutations = 10000, p-value = 0.6568
## alternative hypothesis: equivalence
## null values:
## lower bound upper bound 
##         0.3         0.7 
## 90 percent confidence interval:
##  0.05645152 0.45354848
## sample estimates:
## P(1&gt;2) + .5*P(1=2) 
##              0.255</code></pre>
</div>
<div id="minimal-effect-testing" class="section level3">
<h3>Minimal Effect Testing</h3>
<p>You can also test whether the relative effect falls <em>outside</em>
specified bounds (minimal effect test):</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="co"># Minimal effect test: is the relative effect outside 0.4 to 0.6?</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>               <span class="at">alternative =</span> <span class="st">&quot;minimal.effect&quot;</span>,</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>               <span class="at">mu =</span> <span class="fu">c</span>(<span class="fl">0.4</span>, <span class="fl">0.6</span>))</span></code></pre></div>
<pre><code>## Sample size in at least one group is small. Permutation test (test_method = &#39;perm&#39;) is highly recommended.</code></pre>
<pre><code>## 
##  Two-sample Brunner-Munzel test
## 
## data:  extra by group
## t = -1.2693, df = 16.898, p-value = 0.1108
## alternative hypothesis: minimal.effect
## null values:
## lower bound upper bound 
##         0.4         0.6 
## 90 percent confidence interval:
##  0.0562039 0.4537961
## sample estimates:
## P(1&gt;2) + .5*P(1=2) 
##              0.255</code></pre>
</div>
<div id="paired-samples" class="section level3">
<h3>Paired Samples</h3>
<p>The Brunner-Munzel test can also be applied to paired samples using
the <code>paired</code> argument. Note that for paired samples, the test
is based on a hypothesis of exchangeability:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a><span class="co"># Paired samples test</span></span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">x =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">1</span>],</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>               <span class="at">y =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">2</span>],</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a>               <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## Sample size in at least one group is small. Permutation test (test_method = &#39;perm&#39;) is highly recommended.</code></pre>
<pre><code>## 
##  Exact paired Brunner-Munzel test
## 
## data:  sleep$extra[sleep$group == 1] and sleep$extra[sleep$group == 2]
## t = -3.7266, df = 9, p-value = 0.004722
## alternative hypothesis: true relative effect is not equal to 0.5
## 95 percent confidence interval:
##  0.1062776 0.4037224
## sample estimates:
## P(X&gt;Y) + .5*P(X=Y) 
##              0.255</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="co"># Paired samples with permutation test</span></span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">x =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">1</span>],</span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a>               <span class="at">y =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">2</span>],</span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a>               <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a>               <span class="at">test_method =</span> <span class="st">&quot;perm&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Paired Brunner-Munzel Exact Permutation test
## 
## data:  sleep$extra[sleep$group == 1] and sleep$extra[sleep$group == 2]
## t-observed = -3.7266, N-permutations = 1024, p-value = 0.003906
## alternative hypothesis: true relative effect is not equal to 0.5
## 95 percent confidence interval:
##  0.1233862 0.3866138
## sample estimates:
## P(X&gt;Y) + .5*P(X=Y) 
##              0.255</code></pre>
</div>
<div id="testing-against-a-non-standard-null" class="section level3">
<h3>Testing Against a Non-Standard Null</h3>
<p>You can test against null values other than 0.5:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="co"># Test if the relative effect differs from 0.3</span></span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb31-4"><a href="#cb31-4" tabindex="-1"></a>               <span class="at">mu =</span> <span class="fl">0.3</span>)</span></code></pre></div>
<pre><code>## Sample size in at least one group is small. Permutation test (test_method = &#39;perm&#39;) is highly recommended.</code></pre>
<pre><code>## 
##  Two-sample Brunner-Munzel test
## 
## data:  extra by group
## t = -0.39392, df = 16.898, p-value = 0.6986
## alternative hypothesis: true relative effect is not equal to 0.3
## 95 percent confidence interval:
##  0.01387048 0.49612952
## sample estimates:
## P(1&gt;2) + .5*P(1=2) 
##              0.255</code></pre>
</div>
</div>
<div id="interpreting-brunner-munzel-results" class="section level2">
<h2>Interpreting Brunner-Munzel Results</h2>
<p>When interpreting the Brunner-Munzel test results:</p>
<ol style="list-style-type: decimal">
<li>The relative effect (p-hat) is the primary measure of interest</li>
<li>Values near 0.5 suggest no tendency for one group to produce larger
values than the other</li>
<li>For equivalence testing, you are testing whether this relative
effect falls within your specified bounds</li>
<li>A significant equivalence test suggests that the probability of
superiority is statistically confined to your specified range</li>
</ol>
</div>
<div id="choosing-the-right-test-method" class="section level2">
<h2>Choosing the Right Test Method</h2>
<p><strong>Use <code>test_method = &quot;t&quot;</code> when:</strong></p>
<ul>
<li>Sample sizes are moderate to large (n ≥ 15 per group)</li>
<li>You want the fastest computation</li>
<li>The relative effect estimate is not near the boundaries (0 or
1)</li>
</ul>
<p><strong>Use <code>test_method = &quot;logit&quot;</code> when:</strong></p>
<ul>
<li>The relative effect estimate is close to 0 or 1</li>
<li>You need confidence intervals guaranteed to stay within [0, 1]</li>
<li>Sample sizes are moderate to large</li>
</ul>
<p><strong>Use <code>test_method = &quot;perm&quot;</code> when:</strong></p>
<ul>
<li>Sample sizes are small (n &lt; 15 per group)</li>
<li>You want better Type I error control in small samples</li>
<li>Precision is more important than computational speed</li>
</ul>
<p>Note that the permutation approach can be computationally intensive
for large datasets. Additionally, with a permutation test you may
observe situations where the confidence interval and the p-value would
yield <em>different</em> conclusions.</p>
</div>
<div id="non-inferiority-testing" class="section level2">
<h2>Non-Inferiority Testing</h2>
<p>The Brunner-Munzel test can be used for non-inferiority testing in
clinical trials with ordered categorical data <span class="citation">(Munzel and Hauschke 2003)</span>. By setting
appropriate bounds, you can test whether a new treatment is not
relevantly inferior to a standard:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="co"># Example: test non-inferiority with lower bound of 0.35</span></span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a><span class="co"># (i.e., the new treatment should not be substantially worse)</span></span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a>               <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>,</span>
<span id="cb34-6"><a href="#cb34-6" tabindex="-1"></a>               <span class="at">mu =</span> <span class="fl">0.35</span>)</span></code></pre></div>
<pre><code>## Sample size in at least one group is small. Permutation test (test_method = &#39;perm&#39;) is highly recommended.</code></pre>
<pre><code>## 
##  Two-sample Brunner-Munzel test
## 
## data:  extra by group
## t = -0.83161, df = 16.898, p-value = 0.7914
## alternative hypothesis: true relative effect is greater than 0.35
## 95 percent confidence interval:
##  0.0562039 1.0000000
## sample estimates:
## P(1&gt;2) + .5*P(1=2) 
##              0.255</code></pre>
</div>
</div>
<div id="hodges-lehmann-estimator-and-test" class="section level1">
<h1>Hodges-Lehmann Estimator and Test</h1>
<p>The <code>hodges_lehmann</code> function provides a robust location
test based on the Hodges-Lehmann estimator <span class="citation">(Hodges and Lehmann 1963; Fried and Dehling
2011)</span>. This is a natural companion to the WMW discussion above:
while <code>wilcox_TOST</code> implicitly relies on the location-shift
assumption without making it explicit, <code>hodges_lehmann</code>
directly estimates and tests the location shift parameter with
transparent assumptions.</p>
<div id="why-use-the-hodges-lehmann-estimator" class="section level2">
<h2>Why Use the Hodges-Lehmann Estimator?</h2>
<p>The Hodges-Lehmann estimator has several appealing properties:</p>
<ol style="list-style-type: decimal">
<li><strong>Robustness to outliers</strong> The Hodges-Lehmann estimator
has bounded influence, meaning individual extreme observations cannot
arbitrarily distort the estimate. This provides substantially greater
robustness than the mean while retaining higher efficiency than the
median under normal distributions.</li>
<li><strong>Efficiency:</strong> Under normality, the Hodges-Lehmann
estimator achieves about 95.5% of the efficiency of the sample mean — a
small price for substantial robustness gains.</li>
<li><strong>Transparent assumptions:</strong> Unlike
<code>wilcox_TOST</code>, which requires you to reason about
pseudomedians on the raw scale, the <code>hodges_lehmann</code> function
makes the estimand and test explicit.</li>
</ol>
</div>
<div id="estimators" class="section level2">
<h2>Estimators</h2>
<p>For <strong>one-sample and paired</strong> designs, the function
computes the HL1 estimator — the median of all Walsh averages (pairwise
averages including self-pairs):</p>
<p><span class="math display">\[
\hat{\theta}_{HL1} = \text{med}\left\{\frac{X_i + X_j}{2} : 1 \leq i
\leq j \leq n\right\}
\]</span></p>
<p>For <strong>two-sample</strong> designs, the function computes the
HL2 estimator — the median of all pairwise differences between
samples:</p>
<p><span class="math display">\[
\hat{\Delta}_{HL2} = \text{med}\{Y_j - X_i : i = 1, \ldots, m; \; j = 1,
\ldots, n\}
\]</span></p>
<p>Both estimators are consistent with the pseudomedian and location
shift estimates returned by <code>wilcox.test</code>.</p>
</div>
<div id="test-methods-1" class="section level2">
<h2>Test Methods</h2>
<p>The <code>hodges_lehmann</code> function supports three inference
approaches controlled by the <code>R</code> argument:</p>
<ul>
<li><p><strong>Asymptotic test</strong> (<code>R = NULL</code>, the
default): Uses kernel density estimation to approximate the variance of
the Hodges-Lehmann estimator. Suitable for moderate to large samples (n
<span class="math inline">\(\geq\)</span> 30 per group). Note that this
produces confidence intervals that will differ from
<code>wilcox.test</code> due to the different variance estimation
method.</p></li>
<li><p><strong>Exact permutation test</strong> (<code>R</code> <span class="math inline">\(\geq\)</span> max permutations): Enumerates all
possible permutations and provides exact p-values with no Monte Carlo
error.</p></li>
<li><p><strong>Randomization test</strong> (<code>R</code> &lt; max
permutations): Samples <code>R</code> permutations with replacement.
Uses the (b+1)/(R+1) formula by default for exact Type I error control
<span class="citation">(Phipson and Smyth 2010)</span>.</p></li>
</ul>
</div>
<div id="examples-1" class="section level2">
<h2>Examples</h2>
<div id="basic-two-sample-test-1" class="section level3">
<h3>Basic Two-Sample Test</h3>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&#39;sleep&#39;</span>)</span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a><span class="co"># Asymptotic Hodges-Lehmann test</span></span>
<span id="cb37-4"><a href="#cb37-4" tabindex="-1"></a><span class="fu">hodges_lehmann</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb37-5"><a href="#cb37-5" tabindex="-1"></a>               <span class="at">data =</span> sleep)</span></code></pre></div>
<pre><code>## 
##  Asymptotic Hodges-Lehmann Two Sample Test
## 
## data:  extra by group
## Z = -1.3179, p-value = 0.1875
## alternative hypothesis: true location is not equal to 0
## 95 percent confidence interval:
##  -3.3576425  0.6576425
## sample estimates:
## difference in location 
##                  -1.35</code></pre>
</div>
<div id="permutation-based-test" class="section level3">
<h3>Permutation-Based Test</h3>
<p>For small samples, the permutation approach is recommended:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a><span class="co"># Permutation test</span></span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a><span class="fu">hodges_lehmann</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb39-4"><a href="#cb39-4" tabindex="-1"></a>               <span class="at">R =</span> <span class="dv">1999</span>)</span></code></pre></div>
<pre><code>## 
##  Randomization Hodges-Lehmann Two Sample Test
## 
## data:  extra by group
## Z = -0.72973, p-value = 0.142
## alternative hypothesis: true location is not equal to 0
## 95 percent confidence interval:
##  -3.15  0.50
## sample estimates:
## difference in location 
##                  -1.35</code></pre>
</div>
<div id="equivalence-testing-1" class="section level3">
<h3>Equivalence Testing</h3>
<p>The function directly supports equivalence testing via the
<code>alternative</code> argument. Equivalence bounds are specified on
the pseudomedian (or location shift) scale:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a><span class="co"># Equivalence test: is the location shift within ±2 units?</span></span>
<span id="cb41-2"><a href="#cb41-2" tabindex="-1"></a><span class="fu">hodges_lehmann</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb41-3"><a href="#cb41-3" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb41-4"><a href="#cb41-4" tabindex="-1"></a>               <span class="at">alternative =</span> <span class="st">&quot;equivalence&quot;</span>,</span>
<span id="cb41-5"><a href="#cb41-5" tabindex="-1"></a>               <span class="at">mu =</span> <span class="dv">2</span>,</span>
<span id="cb41-6"><a href="#cb41-6" tabindex="-1"></a>               <span class="at">R =</span> <span class="dv">1999</span>)</span></code></pre></div>
<pre><code>## 
##  Randomization Hodges-Lehmann Two Sample Test
## 
## data:  extra by group
## Z = 0.69348, p-value = 0.284
## alternative hypothesis: equivalence
## null values:
## location location 
##       -2        2 
## 90 percent confidence interval:
##  -2.85  0.10
## sample estimates:
## difference in location 
##                  -1.35</code></pre>
<p><strong>Note on the permutation approach for equivalence
testing:</strong> When using permutation-based inference (i.e.,
<code>R</code> is not <code>NULL</code>), the equivalence and minimal
effect tests use an <em>unstudentized</em> approach. The permutation
distribution of the raw Hodges-Lehmann estimator is generated under the
null hypothesis of exchangeability, and p-values are computed by
comparing the observed estimate’s distance from each equivalence bound
to this distribution. This ensures that the confidence interval and
p-value are always concordant: when the <span class="math inline">\((1 -
2\alpha)\)</span>% CI falls entirely within the equivalence bounds, the
TOST p-value will be less than <span class="math inline">\(\alpha\)</span>, and vice versa. This differs from
the standard alternatives (<code>two.sided</code>, <code>less</code>,
<code>greater</code>), which use a studentized statistic (dividing by a
robust scale estimate). The unstudentized approach is necessary because
the scale estimates S1 and S2 from <span class="citation">Fried and
Dehling (2011)</span> provide numerical stability for standard tests but
do not constitute true studentization for the Hodges-Lehmann
estimator.</p>
<p>By contrast, <code>brunner_munzel</code> and <code>perm_t_test</code>
use studentized permutation approaches for all alternatives because they
have proper standard error estimates.</p>
</div>
<div id="paired-samples-1" class="section level3">
<h3>Paired Samples</h3>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a><span class="co"># Paired Hodges-Lehmann test</span></span>
<span id="cb43-2"><a href="#cb43-2" tabindex="-1"></a><span class="fu">hodges_lehmann</span>(<span class="at">x =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">1</span>],</span>
<span id="cb43-3"><a href="#cb43-3" tabindex="-1"></a>               <span class="at">y =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">2</span>],</span>
<span id="cb43-4"><a href="#cb43-4" tabindex="-1"></a>               <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb43-5"><a href="#cb43-5" tabindex="-1"></a>               <span class="at">R =</span> <span class="dv">1999</span>)</span></code></pre></div>
<pre><code>## Computing all 1024 exact permutations.</code></pre>
<pre><code>## 
##  Exact Permutation Hodges-Lehmann Paired Test
## 
## data:  sleep$extra[sleep$group == 1] and sleep$extra[sleep$group == 2]
## Z = -1.3, p-value &lt; 2.2e-16
## alternative hypothesis: true location is not equal to 0
## 95 percent confidence interval:
##  -1.8 -0.8
## sample estimates:
## pseudomedian of differences 
##                        -1.3</code></pre>
</div>
<div id="minimal-effect-testing-1" class="section level3">
<h3>Minimal Effect Testing</h3>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" tabindex="-1"></a><span class="co"># Minimal effect test: is the location shift outside ±0.5?</span></span>
<span id="cb46-2"><a href="#cb46-2" tabindex="-1"></a><span class="fu">hodges_lehmann</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb46-3"><a href="#cb46-3" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb46-4"><a href="#cb46-4" tabindex="-1"></a>               <span class="at">alternative =</span> <span class="st">&quot;minimal.effect&quot;</span>,</span>
<span id="cb46-5"><a href="#cb46-5" tabindex="-1"></a>               <span class="at">mu =</span> <span class="fl">0.5</span>,</span>
<span id="cb46-6"><a href="#cb46-6" tabindex="-1"></a>               <span class="at">R =</span> <span class="dv">1999</span>)</span></code></pre></div>
<pre><code>## 
##  Randomization Hodges-Lehmann Two Sample Test
## 
## data:  extra by group
## Z = -0.89782, p-value = 0.2215
## alternative hypothesis: minimal.effect
## null values:
## location location 
##     -0.5      0.5 
## 90 percent confidence interval:
##  -2.85  0.15
## sample estimates:
## difference in location 
##                  -1.35</code></pre>
</div>
</div>
<div id="choosing-the-right-approach" class="section level2">
<h2>Choosing the Right Approach</h2>
<p><strong>Use the asymptotic test (<code>R = NULL</code>)
when:</strong></p>
<ul>
<li>Sample sizes are moderate to large (n <span class="math inline">\(\geq\)</span> 30 per group)</li>
<li>You want the fastest computation</li>
<li>Distributions are not extremely heavy-tailed or skewed</li>
</ul>
<p><strong>Use the permutation test (<code>R</code> <span class="math inline">\(\geq\)</span> max permutations) when:</strong></p>
<ul>
<li>Sample sizes are small enough for exact enumeration</li>
<li>You want exact p-values with no Monte Carlo error</li>
<li>For one-sample/paired: <span class="math inline">\(n \leq
16\)</span> (<span class="math inline">\(2^{16}\)</span> = 65,536
permutations)</li>
</ul>
<p><strong>Use the randomization test (set <code>R</code> to a large
number) when:</strong></p>
<ul>
<li>Exact permutation is too computationally expensive</li>
<li>You want distribution-free inference without asymptotic
assumptions</li>
</ul>
</div>
</div>
<div id="resampling-methods-bootstrapping-and-permutation" class="section level1">
<h1>Resampling Methods: Bootstrapping and Permutation</h1>
<p>Resampling methods provide robust alternatives to parametric t-tests
by using the data itself to approximate the sampling distribution of the
test statistic. TOSTER offers two complementary resampling approaches:
bootstrapping and permutation testing. While both methods relax
distributional assumptions, they differ in their mechanics and are
suited to different situations.</p>
<div id="conceptual-overview" class="section level2">
<h2>Conceptual Overview</h2>
<p><strong>Bootstrapping</strong> resamples <em>with replacement</em>
from the observed data to estimate the variability of a statistic. The
bootstrap distribution approximates what we would see if we could
repeatedly sample from the true population. This approach is
particularly useful when you want confidence intervals and effect size
estimates alongside your p-values.</p>
<p><strong>Permutation testing</strong> resamples <em>without
replacement</em> by randomly reassigning observations to groups (or
flipping signs for one-sample/paired tests). Under the null hypothesis
of no difference, group labels are exchangeable, and the permutation
distribution represents the exact null distribution. Permutation tests
provide valid inference even with very small samples where asymptotic
approximations may fail.</p>
</div>
<div id="when-to-use-each-method" class="section level2">
<h2>When to Use Each Method</h2>
<table>
<colgroup>
<col width="25%" />
<col width="47%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th>Scenario</th>
<th>Recommended Method</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Very small samples (paired/one-sample N &lt; 17, two-sample N &lt;
20)</td>
<td>Permutation</td>
<td>Exact permutations are computationally feasible and provide exact
p-values</td>
</tr>
<tr class="even">
<td>Moderate to large samples</td>
<td>Bootstrap</td>
<td>More computationally efficient; provides stable CI estimates</td>
</tr>
<tr class="odd">
<td>Outliers present</td>
<td>Permutation with trimming</td>
<td>Combines exact inference with robust location estimation</td>
</tr>
<tr class="even">
<td>Complex data structures</td>
<td>Bootstrap</td>
<td>More flexible for non-standard designs</td>
</tr>
<tr class="odd">
<td>Publication requiring exact p-values</td>
<td>Permutation (if feasible)</td>
<td>No Monte Carlo error when exact permutations computed</td>
</tr>
</tbody>
</table>
<p>The sample size thresholds above reflect computational practicality.
For one-sample or paired tests, the number of possible sign permutations
is <span class="math inline">\(2^n\)</span>, which equals 65,536 when n
= 16 and jumps to 131,072 at n = 17. For two-sample tests, the number of
possible group assignments is <span class="math inline">\(\binom{n_x +
n_y}{n_x}\)</span>, which grows even faster. When exact enumeration is
feasible, permutation tests yield exact p-values with no Monte Carlo
error.</p>
</div>
</div>
<div id="permutation-t-test" class="section level1">
<h1>Permutation t-test</h1>
<p>The <code>perm_t_test</code> function implements studentized
permutation tests following the approaches of <span class="citation">Janssen (1997)</span> and <span class="citation">Chung
and Romano (2013)</span>. The studentized approach computes a
t-statistic for each permutation, making the test valid even under
heteroscedasticity (unequal variances).</p>
<div id="permutation-procedure" class="section level2">
<h2>Permutation Procedure</h2>
<p>For <strong>one-sample and paired tests</strong>, permutation is
performed by randomly flipping the signs of the centered observations
(or difference scores). Under the null hypothesis that the mean equals
the hypothesized value, positive and negative deviations are equally
likely, making sign assignments exchangeable.</p>
<p>For <strong>two-sample tests</strong>, permutation is performed by
randomly reassigning observations to the two groups. Under the null
hypothesis of no group difference, group membership is arbitrary, making
the labels exchangeable.</p>
</div>
<div id="two-sample-permutation-algorithm" class="section level2">
<h2>Two-Sample Permutation Algorithm</h2>
<p>The studentized permutation test for two independent samples proceeds
as follows:</p>
<ol style="list-style-type: decimal">
<li>Compute the observed test statistic from the original data. For the
standard case (no trimming, unequal variances allowed):</li>
</ol>
<p><span class="math display">\[
t_{obs} = \frac{\bar{x} - \bar{y} - \mu_0}{\sqrt{s_x^2/n_x + s_y^2/n_y}}
\]</span></p>
<p>Where <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(\bar{y}\)</span> are the sample means, <span class="math inline">\(s_x^2\)</span> and <span class="math inline">\(s_y^2\)</span> are the sample variances, <span class="math inline">\(n_x\)</span> and <span class="math inline">\(n_y\)</span> are the sample sizes, and <span class="math inline">\(\mu_0\)</span> is the null hypothesis value
(typically 0).</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Pool the observations: <span class="math inline">\(z = (x_1,
\ldots, x_{n_x}, y_1, \ldots, y_{n_y})\)</span></p></li>
<li><p>For each permutation <span class="math inline">\(b = 1, \ldots,
B\)</span>:</p>
<ul>
<li>Randomly assign <span class="math inline">\(n_x\)</span>
observations to group X and the remaining <span class="math inline">\(n_y\)</span> to group Y</li>
<li>Compute the permutation means <span class="math inline">\(\bar{x}^{*b}\)</span> and <span class="math inline">\(\bar{y}^{*b}\)</span></li>
<li>Compute the permutation variances <span class="math inline">\(s_x^{*2b}\)</span> and <span class="math inline">\(s_y^{*2b}\)</span></li>
<li>Compute the permutation test statistic:</li>
</ul></li>
</ol>
<p><span class="math display">\[
t^{*b} = \frac{\bar{x}^{*b} - \bar{y}^{*b}}{\sqrt{s_x^{*2b}/n_x +
s_y^{*2b}/n_y}}
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>Compute the p-value as the proportion of permutation statistics as
extreme as or more extreme than the observed statistic.</li>
</ol>
<div id="welch-variant-var.equal-false" class="section level3">
<h3>Welch Variant (var.equal = FALSE)</h3>
<p>When <code>var.equal = FALSE</code> (the default), the standard error
is computed separately for each group as shown above. This is the
studentized permutation approach of <span class="citation">Janssen
(1997)</span> and <span class="citation">Chung and Romano (2013)</span>,
which remains valid even when the two populations have different
variances.</p>
</div>
<div id="pooled-variance-variant-var.equal-true" class="section level3">
<h3>Pooled Variance Variant (var.equal = TRUE)</h3>
<p>When <code>var.equal = TRUE</code>, a pooled variance estimate is
used:</p>
<p><span class="math display">\[
s_p^2 = \frac{(n_x - 1)s_x^2 + (n_y - 1)s_y^2}{n_x + n_y - 2}
\]</span></p>
<p><span class="math display">\[
t_{obs} = \frac{\bar{x} - \bar{y} - \mu_0}{s_p\sqrt{1/n_x + 1/n_y}}
\]</span></p>
<p>The same pooled approach is applied to each permutation sample.</p>
</div>
<div id="yuen-variant-tr-0" class="section level3">
<h3>Yuen Variant (tr &gt; 0)</h3>
<p>When <code>tr &gt; 0</code>, the function uses trimmed means and
winsorized variances. Let <span class="math inline">\(g = \lfloor \gamma
\cdot n \rfloor\)</span> be the number of observations trimmed from each
tail (where <span class="math inline">\(\gamma\)</span> is the trimming
proportion), and let <span class="math inline">\(h = n - 2g\)</span> be
the effective sample size.</p>
<p>The trimmed mean is:</p>
<p><span class="math display">\[
\bar{x}_t = \frac{1}{h} \sum_{i=g+1}^{n-g} x_{(i)}
\]</span></p>
<p>where <span class="math inline">\(x_{(i)}\)</span> denotes the <span class="math inline">\(i\)</span>-th order statistic.</p>
<p>The winsorized variance <span class="math inline">\(s_w^2\)</span> is
computed by replacing the <span class="math inline">\(g\)</span>
smallest values with the <span class="math inline">\((g+1)\)</span>-th
smallest and the <span class="math inline">\(g\)</span> largest with the
<span class="math inline">\((n-g)\)</span>-th largest, then computing
the usual variance.</p>
<p>The standard error for Yuen’s test is:</p>
<p><span class="math display">\[
SE = \sqrt{\frac{(n_x - 1) s_{w,x}^2}{h_x(h_x - 1)} + \frac{(n_y - 1)
s_{w,y}^2}{h_y(h_y - 1)}}
\]</span></p>
<p>The test statistic becomes:</p>
<p><span class="math display">\[
t_{obs} = \frac{\bar{x}_t - \bar{y}_t - \mu_0}{SE}
\]</span></p>
<p>This same procedure is applied to each permutation sample, using
trimmed means and winsorized variances computed from the permuted
data.</p>
</div>
</div>
<div id="studentized-permutation-the-perm_se-argument" class="section level2">
<h2>Studentized Permutation: The <code>perm_se</code> Argument</h2>
<p>By default, <code>perm_t_test</code> uses the
<strong>studentized</strong> permutation approach
(<code>perm_se = TRUE</code>), which recalculates the standard error for
each permutation sample. This follows the recommendations of <span class="citation">Janssen (1997)</span> and <span class="citation">Chung
and Romano (2013)</span>, who showed that studentized permutation tests
maintain valid Type I error control even under heteroscedasticity
(unequal variances).</p>
<p><strong>How <code>perm_se</code> and <code>var.equal</code>
interact:</strong></p>
<p>These two arguments control different aspects of the test:</p>
<ul>
<li><code>var.equal</code> controls <strong>how</strong> the standard
error is calculated (pooled vs. Welch formula)</li>
<li><code>perm_se</code> controls <strong>whether</strong> the standard
error is recalculated for each permutation</li>
</ul>
<table>
<colgroup>
<col width="32%" />
<col width="38%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th><code>perm_se</code></th>
<th><code>var.equal</code></th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>TRUE</td>
<td>TRUE</td>
<td>Recalculates pooled variance for each permutation</td>
</tr>
<tr class="even">
<td>TRUE</td>
<td>FALSE</td>
<td>Recalculates separate (Welch) variances for each permutation</td>
</tr>
<tr class="odd">
<td>FALSE</td>
<td>TRUE</td>
<td>Uses original pooled SE for all permutations</td>
</tr>
<tr class="even">
<td>FALSE</td>
<td>FALSE</td>
<td>Uses original Welch SE for all permutations</td>
</tr>
</tbody>
</table>
<p><strong>Recommendations:</strong></p>
<ul>
<li><strong>Use <code>perm_se = TRUE</code> (default)</strong> in most
situations. The studentized approach provides better Type I error
control, especially when variances differ between groups.</li>
<li><strong>Use <code>perm_se = FALSE</code></strong> only when you are
confident that variances are truly equal and want faster computation.
This is the traditional (non-studentized) permutation approach, which
assumes homoscedasticity.</li>
<li>The choice of <code>var.equal</code> should be based on your
substantive knowledge about whether the groups have equal variances.
When in doubt, use the default <code>var.equal = FALSE</code>.</li>
</ul>
</div>
<div id="combining-permutation-with-trimmed-means" class="section level2">
<h2>Combining Permutation with Trimmed Means</h2>
<p>A key feature of <code>perm_t_test</code> is its support for trimmed
means via the <code>tr</code> argument. When <code>tr &gt; 0</code>, the
function uses Yuen’s approach: trimmed means for location estimation and
winsorized variances for standard error calculation. This combination is
particularly powerful because it provides robustness against outliers
(through trimming) together with exact or near-exact inference (through
permutation).</p>
<p>Trimming is helpful when:</p>
<ul>
<li>Data contain outliers or extreme values that would unduly influence
the mean</li>
<li>Distributions have heavy tails</li>
<li>You want robust location estimates without sacrificing the exactness
of permutation inference</li>
</ul>
<p>A common choice is <code>tr = 0.1</code> (10% trimming) or
<code>tr = 0.2</code> (20% trimming), though the optimal amount depends
on the suspected degree of contamination.</p>
</div>
<div id="example-basic-permutation-test" class="section level2">
<h2>Example: Basic Permutation Test</h2>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&#39;sleep&#39;</span>)</span>
<span id="cb48-2"><a href="#cb48-2" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" tabindex="-1"></a><span class="co"># Two-sample permutation t-test</span></span>
<span id="cb48-4"><a href="#cb48-4" tabindex="-1"></a>perm_result <span class="ot">&lt;-</span> <span class="fu">perm_t_test</span>(extra <span class="sc">~</span> group, </span>
<span id="cb48-5"><a href="#cb48-5" tabindex="-1"></a>                           <span class="at">data =</span> sleep,</span>
<span id="cb48-6"><a href="#cb48-6" tabindex="-1"></a>                           <span class="at">R =</span> <span class="dv">1999</span>)</span>
<span id="cb48-7"><a href="#cb48-7" tabindex="-1"></a>perm_result</span></code></pre></div>
<pre><code>## 
##  Randomization Permutation Welch Two Sample t-test
## 
## data:  extra by group
## t-observed = -1.8608, df = 17.776, p-value = 0.0825
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.361  0.160
## sample estimates:
## mean of x mean of y 
##      0.75      2.33</code></pre>
</div>
<div id="example-permutation-test-with-trimming" class="section level2">
<h2>Example: Permutation Test with Trimming</h2>
<p>When outliers are a concern, combining permutation with trimming
provides doubly robust inference:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" tabindex="-1"></a><span class="co"># Simulate data with outliers</span></span>
<span id="cb50-2"><a href="#cb50-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb50-3"><a href="#cb50-3" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">18</span>, <span class="at">mean =</span> <span class="dv">0</span>), <span class="dv">8</span>, <span class="dv">12</span>)  <span class="co"># Two outliers</span></span>
<span id="cb50-4"><a href="#cb50-4" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">20</span>, <span class="at">mean =</span> <span class="dv">0</span>)</span>
<span id="cb50-5"><a href="#cb50-5" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" tabindex="-1"></a><span class="co"># Standard permutation test (sensitive to outliers)</span></span>
<span id="cb50-7"><a href="#cb50-7" tabindex="-1"></a><span class="fu">perm_t_test</span>(x, y, <span class="at">R =</span> <span class="dv">999</span>)</span></code></pre></div>
<pre><code>## Note: Number of permutations (R = 999) is less than 1000. Consider increasing R for more stable p-value estimates.</code></pre>
<pre><code>## 
##  Randomization Permutation Welch Two Sample t-test
## 
## data:  x and y
## t-observed = 1.8777, df = 23.773, p-value = 0.053
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.0004404028 2.9218589227
## sample estimates:
##  mean of x  mean of y 
##  1.2479377 -0.2081052</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" tabindex="-1"></a><span class="co"># Trimmed permutation test (robust to outliers)</span></span>
<span id="cb53-2"><a href="#cb53-2" tabindex="-1"></a><span class="fu">perm_t_test</span>(x, y, <span class="at">tr =</span> <span class="fl">0.1</span>, <span class="at">R =</span> <span class="dv">999</span>)</span></code></pre></div>
<pre><code>## Note: Number of permutations (R = 999) is less than 1000. Consider increasing R for more stable p-value estimates.</code></pre>
<pre><code>## 
##  Randomization Permutation Welch Yuen Two Sample t-test
## 
## data:  x and y
## t-observed = 1.8462, df = 29.997, p-value = 0.078
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.0636125  1.6437612
## sample estimates:
## trimmed mean of x trimmed mean of y 
##         0.5627544        -0.1972272</code></pre>
</div>
<div id="example-equivalence-testing-with-permutation" class="section level2">
<h2>Example: Equivalence Testing with Permutation</h2>
<p>The <code>perm_t_test</code> function supports TOSTER’s equivalence
and minimal effect alternatives:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" tabindex="-1"></a><span class="co"># Equivalence test: is the effect within ±3 units?</span></span>
<span id="cb56-2"><a href="#cb56-2" tabindex="-1"></a><span class="fu">perm_t_test</span>(extra <span class="sc">~</span> group, </span>
<span id="cb56-3"><a href="#cb56-3" tabindex="-1"></a>            <span class="at">data =</span> sleep,</span>
<span id="cb56-4"><a href="#cb56-4" tabindex="-1"></a>            <span class="at">alternative =</span> <span class="st">&quot;equivalence&quot;</span>,</span>
<span id="cb56-5"><a href="#cb56-5" tabindex="-1"></a>            <span class="at">mu =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb56-6"><a href="#cb56-6" tabindex="-1"></a>            <span class="at">R =</span> <span class="dv">999</span>)</span></code></pre></div>
<pre><code>## Note: Number of permutations (R = 999) is less than 1000. Consider increasing R for more stable p-value estimates.</code></pre>
<pre><code>## 
##  Randomization Permutation Welch Two Sample t-test
## 
## data:  extra by group
## t-observed = 1.6724, df = 17.776, p-value = 0.051
## alternative hypothesis: equivalence
## null values:
## difference in means difference in means 
##                  -3                   3 
## 90 percent confidence interval:
##  -3.060 -0.138
## sample estimates:
## mean of x mean of y 
##      0.75      2.33</code></pre>
</div>
<div id="exact-vs.-monte-carlo-permutations" class="section level2">
<h2>Exact vs. Monte Carlo Permutations</h2>
<p>When the total number of possible permutations is less than or equal
to <code>R</code>, the function automatically computes all exact
permutations and prints a message. For example, with a paired sample of
n = 10, there are <span class="math inline">\(2^{10} = 1024\)</span>
possible sign permutations, so requesting <code>R = 1999</code> would
trigger exact computation.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" tabindex="-1"></a><span class="co"># Small paired sample - exact permutations will be computed</span></span>
<span id="cb59-2"><a href="#cb59-2" tabindex="-1"></a>before <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">4.8</span>, <span class="fl">6.2</span>, <span class="fl">5.7</span>, <span class="fl">6.0</span>, <span class="fl">5.5</span>, <span class="fl">4.9</span>, <span class="fl">5.8</span>)</span>
<span id="cb59-3"><a href="#cb59-3" tabindex="-1"></a>after <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">5.6</span>, <span class="fl">5.2</span>, <span class="fl">6.7</span>, <span class="fl">6.1</span>, <span class="fl">6.5</span>, <span class="fl">5.8</span>, <span class="fl">5.3</span>, <span class="fl">6.2</span>)</span>
<span id="cb59-4"><a href="#cb59-4" tabindex="-1"></a></span>
<span id="cb59-5"><a href="#cb59-5" tabindex="-1"></a><span class="fu">perm_t_test</span>(<span class="at">x =</span> before, <span class="at">y =</span> after,</span>
<span id="cb59-6"><a href="#cb59-6" tabindex="-1"></a>            <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb59-7"><a href="#cb59-7" tabindex="-1"></a>            <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>,</span>
<span id="cb59-8"><a href="#cb59-8" tabindex="-1"></a>            <span class="at">R =</span> <span class="dv">999</span>)</span></code></pre></div>
<pre><code>## Computing all 256 exact permutations.</code></pre>
<pre><code>## 
##  Exact Permutation Paired t-test
## 
## data:  before and after
## t-observed = -17, df = 7, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##     -Inf -0.3875
## sample estimates:
## mean of the differences 
##                  -0.425</code></pre>
</div>
</div>
<div id="bootstrap-t-test" class="section level1">
<h1>Bootstrap t-test</h1>
<p>The <code>boot_t_TOST</code> function provides bootstrap-based
inference using the percentile bootstrap approach outlined by <span class="citation">Efron and Tibshirani (1993)</span> (see chapter 16).
The bootstrapped p-values are derived from the studentized version of a
test of mean differences. Overall, the results should be similar to
<code>t_TOST</code> but with greater robustness to distributional
violations.</p>
<div id="advantages-of-bootstrapping" class="section level2">
<h2>Advantages of Bootstrapping</h2>
<p>Bootstrap methods offer several advantages for equivalence
testing:</p>
<ol style="list-style-type: decimal">
<li>They make minimal assumptions about the underlying data
distribution</li>
<li>They are robust to deviations from normality</li>
<li>They provide realistic confidence intervals even with small
samples</li>
<li>They can handle complex data structures and dependencies</li>
<li>They often provide more accurate results when parametric assumptions
are violated</li>
</ol>
</div>
<div id="bootstrap-algorithm-two-sample-case" class="section level2">
<h2>Bootstrap Algorithm (Two-Sample Case)</h2>
<ol style="list-style-type: decimal">
<li><p>Form B bootstrap data sets from x* and y* wherein x* is sampled
with replacement from <span class="math inline">\(\tilde x_1,\tilde x_2,
... \tilde x_n\)</span> and y* is sampled with replacement from <span class="math inline">\(\tilde y_1,\tilde y_2, ... \tilde y_n\)</span></p>
<p>Where:</p>
<ul>
<li>B is the number of bootstrap replications (set using the
<code>R</code> parameter)</li>
<li><span class="math inline">\(\tilde x_i\)</span> and <span class="math inline">\(\tilde y_i\)</span> represent the original
observations in each group</li>
</ul></li>
<li><p>t is then evaluated on each sample, but the mean of each sample
(y or x) and the overall average (z) are subtracted from each</p></li>
</ol>
<p><span class="math display">\[
t(z^{*b}) = \frac {(\bar x^*-\bar x - \bar z) - (\bar y^*-\bar y - \bar
z)}{\sqrt {sd_y^*/n_y + sd_x^*/n_x}}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\bar x^*\)</span> and <span class="math inline">\(\bar y^*\)</span> are the means of the bootstrap
samples</li>
<li><span class="math inline">\(\bar x\)</span> and <span class="math inline">\(\bar y\)</span> are the means of the original
samples</li>
<li><span class="math inline">\(\bar z\)</span> is the overall mean</li>
<li><span class="math inline">\(sd_x^*\)</span> and <span class="math inline">\(sd_y^*\)</span> are the standard deviations of the
bootstrap samples</li>
<li><span class="math inline">\(n_x\)</span> and <span class="math inline">\(n_y\)</span> are the sample sizes</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>An approximate p-value can then be calculated as the number of
bootstrapped results greater than the observed t-statistic from the
sample.</li>
</ol>
<p><span class="math display">\[
p_{boot} = \frac {\#t(z^{*b}) \ge t_{sample}}{B}
\]</span></p>
<p>Where: - <span class="math inline">\(\#t(z^{*b}) \ge
t_{sample}\)</span> is the count of bootstrap t-statistics that exceed
the observed t-statistic - B is the total number of bootstrap
replications</p>
<p>The same process is completed for the one sample case but with the
one sample solution for the equation outlined by <span class="math inline">\(t(z^{*b})\)</span>. The paired sample case in this
bootstrap procedure is equivalent to the one sample solution because the
test is based on the difference scores.</p>
</div>
<div id="choosing-the-number-of-bootstrap-replications" class="section level2">
<h2>Choosing the Number of Bootstrap Replications</h2>
<p>When using bootstrap methods, the choice of replications (the
<code>R</code> parameter) is important:</p>
<ul>
<li><strong>R = 999 or 1999</strong>: Recommended for standard
analyses</li>
<li><strong>R = 4999 or 9999</strong>: Recommended for
publication-quality results or when precise p-values are needed</li>
<li><strong>R &lt; 500</strong>: Acceptable only for exploratory
analyses or when computational resources are limited</li>
</ul>
<p>Larger values of R provide more stable results but increase
computation time. For most purposes, 999 or 1999 replications strike a
good balance between precision and computational efficiency.</p>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<p>We can use the sleep data to see the bootstrapped results. Notice
that the plots show how the re-sampling via bootstrapping indicates the
instability of Hedges’s d<sub>z</sub>.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&#39;sleep&#39;</span>)</span>
<span id="cb62-2"><a href="#cb62-2" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" tabindex="-1"></a><span class="co"># For paired tests with bootstrap methods, use separate vectors</span></span>
<span id="cb62-4"><a href="#cb62-4" tabindex="-1"></a>test1 <span class="ot">=</span> <span class="fu">boot_t_TOST</span>(<span class="at">x =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">1</span>],</span>
<span id="cb62-5"><a href="#cb62-5" tabindex="-1"></a>                    <span class="at">y =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">2</span>],</span>
<span id="cb62-6"><a href="#cb62-6" tabindex="-1"></a>                      <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb62-7"><a href="#cb62-7" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>,</span>
<span id="cb62-8"><a href="#cb62-8" tabindex="-1"></a>                    <span class="at">R =</span> <span class="dv">499</span>)</span>
<span id="cb62-9"><a href="#cb62-9" tabindex="-1"></a></span>
<span id="cb62-10"><a href="#cb62-10" tabindex="-1"></a></span>
<span id="cb62-11"><a href="#cb62-11" tabindex="-1"></a><span class="fu">print</span>(test1)</span></code></pre></div>
<pre><code>## 
## Bootstrapped Paired t-test
## 
## The equivalence test was non-significant, t(9) = -2.777, p = 1e+00
## The null hypothesis test was significant, t(9) = -4.062, p = 0e+00
## NHST: reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##                 t df p.value
## t-test     -4.062  9 &lt; 0.001
## TOST Lower -2.777  9       1
## TOST Upper -5.348  9 &lt; 0.001
## 
## Effect Sizes 
##               Estimate     SE               C.I. Conf. Level
## Raw             -1.580 0.3786 [-3.0262, -1.0343]         0.9
## Hedges&#39;s g(z)   -1.174 0.7657   [-1.3935, 1.252]         0.9
## Note: studentized bootstrap ci method utilized.</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" tabindex="-1"></a><span class="fu">plot</span>(test1)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<div id="interpreting-bootstrap-tost-results" class="section level3">
<h3>Interpreting Bootstrap TOST Results</h3>
<p>When interpreting the results of <code>boot_t_TOST</code>:</p>
<ol style="list-style-type: decimal">
<li>The bootstrap p-values (<code>p1</code> and <code>p2</code>)
represent the empirical probability of observing the test statistic or
more extreme values under repeated sampling</li>
<li>The confidence intervals are derived directly from the empirical
distribution of bootstrap samples</li>
<li>The distribution plots provide visual insight into the variability
of the effect size estimate</li>
</ol>
<p>For equivalence testing, examine whether both bootstrap p-values are
significant (&lt; alpha) and whether the confidence interval for the
effect size falls entirely within the equivalence bounds.</p>
</div>
</div>
</div>
<div id="comparing-bootstrap-and-permutation-approaches" class="section level1">
<h1>Comparing Bootstrap and Permutation Approaches</h1>
<p>To illustrate the similarities and differences between these methods,
let’s apply both to the same dataset:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" tabindex="-1"></a><span class="co"># Same equivalence test using both methods</span></span>
<span id="cb65-2"><a href="#cb65-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&#39;sleep&#39;</span>)</span>
<span id="cb65-3"><a href="#cb65-3" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" tabindex="-1"></a><span class="co"># Bootstrap approach</span></span>
<span id="cb65-5"><a href="#cb65-5" tabindex="-1"></a>boot_result <span class="ot">&lt;-</span> <span class="fu">boot_t_test</span>(extra <span class="sc">~</span> group, </span>
<span id="cb65-6"><a href="#cb65-6" tabindex="-1"></a>                           <span class="at">data =</span> sleep,</span>
<span id="cb65-7"><a href="#cb65-7" tabindex="-1"></a>                           <span class="at">alternative =</span> <span class="st">&quot;equivalence&quot;</span>,</span>
<span id="cb65-8"><a href="#cb65-8" tabindex="-1"></a>                           <span class="at">mu =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb65-9"><a href="#cb65-9" tabindex="-1"></a>                           <span class="at">R =</span> <span class="dv">999</span>)</span>
<span id="cb65-10"><a href="#cb65-10" tabindex="-1"></a></span>
<span id="cb65-11"><a href="#cb65-11" tabindex="-1"></a><span class="co"># Permutation approach  </span></span>
<span id="cb65-12"><a href="#cb65-12" tabindex="-1"></a>perm_result <span class="ot">&lt;-</span> <span class="fu">perm_t_test</span>(extra <span class="sc">~</span> group,</span>
<span id="cb65-13"><a href="#cb65-13" tabindex="-1"></a>                           <span class="at">data =</span> sleep,</span>
<span id="cb65-14"><a href="#cb65-14" tabindex="-1"></a>                           <span class="at">alternative =</span> <span class="st">&quot;equivalence&quot;</span>, </span>
<span id="cb65-15"><a href="#cb65-15" tabindex="-1"></a>                           <span class="at">mu =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb65-16"><a href="#cb65-16" tabindex="-1"></a>                           <span class="at">R =</span> <span class="dv">999</span>)</span></code></pre></div>
<pre><code>## Note: Number of permutations (R = 999) is less than 1000. Consider increasing R for more stable p-value estimates.</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" tabindex="-1"></a><span class="co"># Compare results</span></span>
<span id="cb67-2"><a href="#cb67-2" tabindex="-1"></a>boot_result</span></code></pre></div>
<pre><code>## 
##  Bootstrapped Welch Two Sample t-test
## 
## data:  extra by group
## t-observed = 0.49465, df = 17.776, p-value = 0.2903
## alternative hypothesis: equivalence
## null values:
## difference in means difference in means 
##                  -2                   2 
## 90 percent confidence interval:
##  -3.0970524 -0.1114282
## sample estimates:
## mean of x mean of y 
##      0.75      2.33</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" tabindex="-1"></a>perm_result</span></code></pre></div>
<pre><code>## 
##  Randomization Permutation Welch Two Sample t-test
## 
## data:  extra by group
## t-observed = 0.49465, df = 17.776, p-value = 0.307
## alternative hypothesis: equivalence
## null values:
## difference in means difference in means 
##                  -2                   2 
## 90 percent confidence interval:
##  -3.120 -0.078
## sample estimates:
## mean of x mean of y 
##      0.75      2.33</code></pre>
<p>Both methods test the same hypothesis and should yield similar
conclusions. Key differences to note:</p>
<ul>
<li><strong>P-values</strong>: May differ slightly due to Monte Carlo
variability and the different resampling mechanisms</li>
<li><strong>Confidence intervals</strong>: Bootstrap uses the resampled
effect distribution; permutation uses the percentile method on permuted
effects</li>
<li><strong>Exact inference</strong>: When sample sizes are small
enough, permutation provides exact p-values with no Monte Carlo
error</li>
</ul>
<div id="summary-choosing-between-methods" class="section level2">
<h2>Summary: Choosing Between Methods</h2>
<table>
<colgroup>
<col width="14%" />
<col width="43%" />
<col width="42%" />
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Permutation (<code>perm_t_test</code>)</th>
<th>Bootstrap (<code>boot_t_TOST</code>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Resampling type</td>
<td>Without replacement</td>
<td>With replacement</td>
</tr>
<tr class="even">
<td>Exact p-values possible</td>
<td>Yes (small samples)</td>
<td>No</td>
</tr>
<tr class="odd">
<td>Trimmed means support</td>
<td>Yes (<code>tr</code> argument)</td>
<td>No</td>
</tr>
<tr class="even">
<td>Effect size plots</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Best for</td>
<td>Small samples, exact inference</td>
<td>Moderate samples, visualization</td>
</tr>
</tbody>
</table>
<p>For very small samples where exact permutations are feasible,
permutation testing is generally preferred because it provides exact
p-values (i.e., no need to set a seed). For larger samples or when you
want the visualization capabilities of <code>boot_t_TOST</code>,
bootstrapping is a good choice. When outliers are a concern, using
<code>perm_t_test</code> with trimming combines the benefits of exact
inference with robust location estimation.</p>
</div>
</div>
<div id="ratio-of-difference-log-transformed" class="section level1">
<h1>Ratio of Difference (Log Transformed)</h1>
<p>In many bioequivalence studies, the differences between drugs are
compared on the log scale <span class="citation">(He et al.
2022)</span>. The log scale allows researchers to compare the ratio of
two means.</p>
<p><span class="math display">\[
log ( \frac{y}{x} ) = log(y) - log(x)
\]</span></p>
<p>Where: - y and x are the means of the two groups being compared - The
transformation converts multiplicative relationships into additive
ones</p>
<div id="why-use-the-natural-log-transformation" class="section level2">
<h2>Why Use The Natural Log Transformation?</h2>
<p>The <a href="https://www.fda.gov/regulatory-information/search-fda-guidance-documents/bioavailability-and-bioequivalence-studies-submitted-ndas-or-inds-general-considerations">United
States Food and Drug Administration (FDA)</a><a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> has stated a rationale
for using the log transformed values:</p>
<blockquote>
<p>Using logarithmic transformation, the general linear statistical
model employed in the analysis of BE data allows inferences about the
difference between the two means on the log scale, which can then be
retransformed into inferences about the ratio of the two averages (means
or medians) on the original scale. Logarithmic transformation thus
achieves a general comparison based on the ratio rather than the
differences.</p>
</blockquote>
<p>Log transformation offers several advantages:</p>
<ol style="list-style-type: decimal">
<li>It facilitates the analysis of <strong>relative</strong> rather than
absolute differences</li>
<li>It often makes right-skewed distributions more symmetric</li>
<li>It stabilizes variance when variability increases with the mean</li>
<li>It provides an easy-to-interpret effect size (ratio of means)</li>
</ol>
<p>In addition, the FDA considers two drugs as bioequivalent when the
ratio between x and y is less than 1.25 and greater than 0.8 (1/1.25),
which is the default equivalence bound for the log functions.</p>
</div>
<div id="applications-beyond-bioequivalence" class="section level2">
<h2>Applications Beyond Bioequivalence</h2>
<p>While log transformation is standard in bioequivalence studies, it’s
useful in many other contexts:</p>
<ul>
<li><strong>Economics</strong>: Comparing percentage changes in economic
indicators</li>
<li><strong>Environmental science</strong>: Analyzing concentration
ratios of pollutants</li>
<li><strong>Biology</strong>: Examining growth rates or concentration
ratios</li>
<li><strong>Medicine</strong>: Comparing relative efficacy of
treatments</li>
<li><strong>Psychology</strong>: Analyzing response time ratios</li>
</ul>
<p>Consider using log transformation whenever your research question is
about relative rather than absolute differences, particularly when the
data follow a multiplicative rather than additive pattern.</p>
</div>
<div id="log_tost" class="section level2">
<h2>log_TOST</h2>
<p>For example, we could compare whether the cars of different
transmissions are “equivalent” with regards to gas mileage. We can use
the default equivalence bounds (<code>eqb = 1.25</code>).</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" tabindex="-1"></a><span class="fu">log_TOST</span>(</span>
<span id="cb71-2"><a href="#cb71-2" tabindex="-1"></a>  mpg <span class="sc">~</span> am,</span>
<span id="cb71-3"><a href="#cb71-3" tabindex="-1"></a>  <span class="at">data =</span> mtcars</span>
<span id="cb71-4"><a href="#cb71-4" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## 
## Log-transformed Welch Two Sample t-test
## 
## The equivalence test was non-significant, t(23.96) = -1.363, p = 9.07e-01
## The null hypothesis test was significant, t(23.96) = -3.826, p = 8.19e-04
## NHST: reject null significance hypothesis that the effect is equal to one 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##                 t    df p.value
## t-test     -3.826 23.96 &lt; 0.001
## TOST Lower -1.363 23.96   0.907
## TOST Upper -6.288 23.96 &lt; 0.001
## 
## Effect Sizes 
##                  Estimate      SE               C.I. Conf. Level
## log(Means Ratio)  -0.3466 0.09061 [-0.5017, -0.1916]         0.9
## Means Ratio        0.7071      NA   [0.6055, 0.8256]         0.9</code></pre>
<p>Note, that the function produces t-tests similar to the
<code>t_TOST</code> function, but provides two effect sizes. The means
ratio on the log scale (the scale of the test statistics), and the means
ratio. The means ratio is missing standard error because the confidence
intervals and estimate are simply the log scale results
exponentiated.</p>
<div id="interpreting-the-means-ratio" class="section level3">
<h3>Interpreting the Means Ratio</h3>
<p>When interpreting the means ratio:</p>
<ul>
<li>A ratio of 1.0 indicates perfect equivalence (no difference)</li>
<li>Ratios &gt; 1.0 indicate that the first group has higher values than
the second</li>
<li>Ratios &lt; 1.0 indicate that the first group has lower values than
the second</li>
</ul>
<p>For equivalence testing with the default bounds (0.8, 1.25): -
Equivalence is established when the 90% confidence interval for the
ratio falls entirely within (0.8, 1.25) - This range corresponds to a
difference of ±20% on a relative scale</p>
</div>
</div>
<div id="bootstrap-log" class="section level2">
<h2>Bootstrap + Log</h2>
<p>However, it has been noted in the statistics literature that t-tests
on the logarithmic scale can be biased, and it is recommended that
bootstrapped tests be utilized instead. Therefore, the
<code>boot_log_TOST</code> function can be utilized to perform a more
precise test.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" tabindex="-1"></a><span class="fu">boot_log_TOST</span>(</span>
<span id="cb73-2"><a href="#cb73-2" tabindex="-1"></a>  mpg <span class="sc">~</span> am,</span>
<span id="cb73-3"><a href="#cb73-3" tabindex="-1"></a>  <span class="at">data =</span> mtcars,</span>
<span id="cb73-4"><a href="#cb73-4" tabindex="-1"></a>  <span class="at">R =</span> <span class="dv">499</span></span>
<span id="cb73-5"><a href="#cb73-5" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## 
## Bootstrapped Log Welch Two Sample t-test
## 
## The equivalence test was non-significant, t(23.96) = -1.363, p = 9.62e-01
## The null hypothesis test was significant, t(23.96) = -3.826, p = 0e+00
## NHST: reject null significance hypothesis that the effect is equal to 1 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##                 t    df p.value
## t-test     -3.826 23.96 &lt; 0.001
## TOST Lower -1.363 23.96   0.962
## TOST Upper -6.288 23.96 &lt; 0.001
## 
## Effect Sizes 
##                  Estimate      SE              C.I. Conf. Level
## log(Means Ratio)  -0.3466 0.08487 [-0.532, -0.1774]         0.9
## Means Ratio        0.7071 0.06060  [0.5874, 0.8375]         0.9
## Note: studentized bootstrap ci method utilized.</code></pre>
<p>The bootstrapped version is particularly recommended when:</p>
<ul>
<li>Sample sizes are small (n &lt; 30 per group)</li>
<li>Data show notable deviations from log-normality</li>
<li>You want to ensure robust confidence intervals</li>
</ul>
</div>
</div>
<div id="standardized-effect-sizes-estimation-and-testing" class="section level1">
<h1>Standardized Effect Sizes: Estimation and Testing</h1>
<p>The <code>ses_calc</code> and <code>boot_ses_calc</code> functions
calculate non-parametric standardized effect sizes (rank-biserial
correlation, WMW odds, concordance probability, or log-odds) with
confidence intervals<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. As of v0.9.0, <code>ses_calc</code> also
supports hypothesis testing directly on the effect size scale.</p>
<div id="available-effect-sizes" class="section level2">
<h2>Available Effect Sizes</h2>
<div id="rank-biserial-correlation" class="section level3">
<h3>Rank-Biserial Correlation</h3>
<p>The rank-biserial correlation is a fairly intuitive measure of effect
size which has the same interpretation as the common language effect
size <span class="citation">(Kerby 2014)</span>. However, instead of
assuming normality and equal variances, it calculates the number of
favorable (positive) and unfavorable (negative) pairs based on their
respective ranks.</p>
<p>For the two sample case, the correlation is calculated as the
proportion of favorable pairs minus the unfavorable pairs.</p>
<p><span class="math display">\[
r_{biserial} = f_{pairs} - u_{pairs}
\]</span></p>
<p>Where: - <span class="math inline">\(f_{pairs}\)</span> is the
proportion of favorable pairs - <span class="math inline">\(u_{pairs}\)</span> is the proportion of
unfavorable pairs</p>
<p>For the one sample or paired samples cases, the correlation is
calculated with ties (values equal to zero) not being dropped. This
provides a <em>conservative</em> estimate of the rank biserial
correlation.</p>
<p>It is calculated in the following steps wherein <span class="math inline">\(z\)</span> represents the values or difference
between paired observations:</p>
<ol style="list-style-type: decimal">
<li>Calculate signed ranks:</li>
</ol>
<p><span class="math display">\[
r_j = -1 \cdot sign(z_j) \cdot rank(|z_j|)
\]</span></p>
<p>Where: - <span class="math inline">\(r_j\)</span> is the signed rank
for observation <span class="math inline">\(j\)</span> - <span class="math inline">\(sign(z_j)\)</span> is the sign of observation
<span class="math inline">\(z_j\)</span> (+1 or -1) - <span class="math inline">\(rank(|z_j|)\)</span> is the rank of the absolute
value of observation <span class="math inline">\(z_j\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Calculate the positive and negative sums:</li>
</ol>
<p><span class="math display">\[
    R_{+} = \sum_{1\le i \le n, \space z_i &gt; 0}r_j
\]</span></p>
<p><span class="math display">\[
    R_{-} = \sum_{1\le i \le n, \space z_i &lt; 0}r_j
\]</span></p>
<p>Where: - <span class="math inline">\(R_{+}\)</span> is the sum of
ranks for positive observations - <span class="math inline">\(R_{-}\)</span> is the sum of ranks for negative
observations</p>
<ol start="3" style="list-style-type: decimal">
<li>Determine the smaller of the two rank sums:</li>
</ol>
<p><span class="math display">\[
T = min(R_{+}, \space R_{-})
\]</span></p>
<p><span class="math display">\[
S = \begin{cases} -4 &amp; R_{+} \ge R_{-} \\ 4 &amp; R_{+} &lt; R_{-}
\end{cases}
\]</span></p>
<p>Where: - <span class="math inline">\(T\)</span> is the smaller of the
two rank sums - <span class="math inline">\(S\)</span> is a sign factor
based on which rank sum is smaller</p>
<ol start="4" style="list-style-type: decimal">
<li>Calculate rank-biserial correlation:</li>
</ol>
<p><span class="math display">\[
r_{biserial} = S \cdot | \frac{\frac{T - \frac{(R_{+} +
R_{-})}{2}}{n}}{n + 1} |
\]</span></p>
<p>Where: - <span class="math inline">\(n\)</span> is the number of
observations (or pairs) - The final value ranges from -1 to 1</p>
</div>
<div id="concordance-probability" class="section level3">
<h3>Concordance Probability</h3>
<p>The concordance probability (also known as the c-statistic, c-index,
or probability of superiority<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>) is converted from the rank-biserial
correlation:</p>
<p><span class="math display">\[
c = \frac{(r_{biserial} + 1)}{2}
\]</span></p>
<p>The c-statistic can be interpreted as the probability that a randomly
selected observation from one group will be greater than a randomly
selected observation from another group. A value of 0.5 indicates no
difference between groups, while values approaching 1 indicate perfect
separation between groups.</p>
<p>Please note that the c-statistic is equivalent to the area under the
receiver operating characteristic curve (AUC) in binary classification
contexts. Additionally, the c-statistic is the same estimate that is
produced by <code>brunner_munzel</code> with the exception of paired
samples and one sample designs. Additionally, the CI and SE methods
differ.</p>
</div>
<div id="wmw-odds" class="section level3">
<h3>WMW Odds</h3>
<p>The Wilcoxon-Mann-Whitney odds <span class="citation">(O’Brien and
Castelloe 2006)</span>, also known as the “Generalized Odds Ratio”<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> <span class="citation">(Agresti 1980)</span>, is calculated by converting the
c-statistic:</p>
<p><span class="math display">\[
WMW_{odds} = e^{logit(c)}
\]</span></p>
<p>Where <span class="math inline">\(logit(c) =
\ln\frac{c}{1-c}\)</span></p>
<p>The WMW odds can be interpreted similarly to a traditional odds
ratio, representing the odds that an observation from one group is
greater than an observation from another group.</p>
</div>
<div id="guidelines-for-selecting-effect-size-measures" class="section level3">
<h3>Guidelines for Selecting Effect Size Measures</h3>
<ul>
<li><strong>Rank-biserial correlation (<code>&quot;rb&quot;</code>)</strong> is
useful when you want a correlation-like measure that’s easily
interpretable and comparable to other correlation coefficients.</li>
<li><strong>Concordance probability (<code>&quot;cstat&quot;</code>)</strong> is
beneficial when you want to express the effect in terms of probability,
making it accessible to non-statisticians.</li>
<li><strong>WMW odds (<code>&quot;odds&quot;</code>)</strong> is helpful when you
want to express the effect in terms familiar to those who work with odds
ratios in logistic regression or epidemiology, or interpreting
probabilities as odds (e.g., betting and prediction markets).</li>
<li><strong>WMW log-odds (<code>&quot;logodds&quot;</code>)</strong> the log-odds
can be helpful because you <em>could</em> interpret them as a percent
difference/change in the odds of stochastic superiority. E.g., if the
WMW log-odds were 0.10 then you could say “X increases the odds of
superiority by approximately 10% over Y”.</li>
</ul>
</div>
</div>
<div id="confidence-interval-methods" class="section level2">
<h2>Confidence Interval Methods</h2>
<p>As of v0.9.0, the TOSTER package defaults to the
<strong>Agresti</strong> method (<code>se_method = &quot;agresti&quot;</code>) for
computing standard errors and confidence intervals for all SES
functions. This method uses placement-based variance estimation and
conducts inference on the log-odds scale, which has better asymptotic
properties (the log-odds scale is unbounded and converges to normality
faster). Results are back-transformed to the requested effect size scale
for reporting.</p>
<p>The <strong>Fisher z-transformation</strong> method
(<code>se_method = &quot;fisher&quot;</code>) remains available as a legacy
option. This was the default in earlier versions of the package and is
documented below for reference.</p>
<div id="fisher-z-transformation-legacy-method" class="section level3">
<h3>Fisher z-Transformation (Legacy Method)</h3>
<p>The Fisher approximation calculates confidence intervals by first
computing a standard error, then transforming to a Fisher z-scale for
interval construction.</p>
<p>For paired samples, or one sample, the standard error is calculated
as:</p>
<p><span class="math display">\[
SE_r = \sqrt{ \frac {(2 \cdot nd^3 + 3 \cdot nd^2 + nd) / 6} {(nd^2 +
nd) / 2} }
\]</span></p>
<p>wherein, nd represents the total number of observations (or
pairs).</p>
<p>For independent samples, the standard error is:</p>
<p><span class="math display">\[
SE_r = \sqrt{\frac {(n1 + n2 + 1)} { (3 \cdot n1 \cdot n2)}}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(n1\)</span> and <span class="math inline">\(n2\)</span> are the sample sizes of the two
groups</li>
</ul>
<p>The confidence intervals are then calculated by transforming the
estimate:</p>
<p><span class="math display">\[
r_z = atanh(r_{biserial})
\]</span></p>
<p>Then the confidence interval can be calculated and back
transformed:</p>
<p><span class="math display">\[
r_{CI} = tanh(r_z  \pm  Z_{(1 - \alpha / 2)} \cdot SE_r)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(Z_{(1 - \alpha / 2)}\)</span> is the
critical value from the standard normal distribution</li>
<li><span class="math inline">\(\alpha\)</span> is the significance
level (typically 0.05)</li>
</ul>
</div>
</div>
<div id="effect-size-estimation" class="section level2">
<h2>Effect Size Estimation</h2>
<p>The interface is similar to <code>wilcox_TOST</code>, but rather than
setting equivalence bounds on the raw scale, <code>ses_calc</code> works
directly with the standardized effect size. By default (with
<code>alternative = &quot;none&quot;</code>), it returns an effect size estimate
and confidence interval with no hypothesis test:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" tabindex="-1"></a><span class="co"># Rank-biserial correlation for paired data</span></span>
<span id="cb75-2"><a href="#cb75-2" tabindex="-1"></a><span class="fu">ses_calc</span>(<span class="at">x =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">1</span>],</span>
<span id="cb75-3"><a href="#cb75-3" tabindex="-1"></a>         <span class="at">y =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">2</span>],</span>
<span id="cb75-4"><a href="#cb75-4" tabindex="-1"></a>         <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb75-5"><a href="#cb75-5" tabindex="-1"></a>         <span class="at">ses =</span> <span class="st">&quot;rb&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Paired Sample Rank-Biserial Correlation estimate with CI
## 
## data:  sleep$extra[sleep$group == 1] and sleep$extra[sleep$group == 2]
## 
## alternative hypothesis: none
## 95 percent confidence interval:
##  -1  1
## sample estimates:
## Rank-Biserial Correlation 
##                 0.9818182</code></pre>
<p>The bootstrapped version provides a resampling-based alternative:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" tabindex="-1"></a><span class="co"># Setting bootstrap replications low to</span></span>
<span id="cb77-2"><a href="#cb77-2" tabindex="-1"></a><span class="do">## reduce compiling time of vignette</span></span>
<span id="cb77-3"><a href="#cb77-3" tabindex="-1"></a><span class="fu">boot_ses_calc</span>(<span class="at">x =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">1</span>],</span>
<span id="cb77-4"><a href="#cb77-4" tabindex="-1"></a>              <span class="at">y =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">2</span>],</span>
<span id="cb77-5"><a href="#cb77-5" tabindex="-1"></a>         <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb77-6"><a href="#cb77-6" tabindex="-1"></a>         <span class="at">R =</span> <span class="dv">199</span>,</span>
<span id="cb77-7"><a href="#cb77-7" tabindex="-1"></a>         <span class="at">boot_ci =</span> <span class="st">&quot;perc&quot;</span>, <span class="co"># recommend percentile bootstrap for paired SES</span></span>
<span id="cb77-8"><a href="#cb77-8" tabindex="-1"></a>         <span class="at">ses =</span> <span class="st">&quot;rb&quot;</span>)</span></code></pre></div>
<pre><code>## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.
## Complete separation detected (p = 0 or 1). A continuity correction of 0.5/(number of pairs) was applied. Point estimates and hypothesis tests are approximate.</code></pre>
<pre><code>## Bootstrapped results contain extreme results (i.e., no overlap), caution advised interpreting confidence intervals.</code></pre>
<pre><code>## 
##  Bootstrapped Paired Sample Rank-Biserial Correlation estimate with CI
## 
## data:  sleep$extra[sleep$group == 1] and sleep$extra[sleep$group == 2]
## 
## alternative hypothesis: none
## 95 percent confidence interval:
##  0.8909091 1.0000000
## sample estimates:
## Rank-Biserial Correlation 
##                 0.9818182</code></pre>
<div id="choosing-between-bootstrap-ci-methods" class="section level3">
<h3>Choosing Between Bootstrap CI Methods</h3>
<p>The <code>boot_ses_calc</code> function offers several bootstrap
confidence interval methods through the <code>boot_ci</code>
parameter:</p>
<ul>
<li><strong>“perc”</strong> (Percentile): Simple and intuitive, works
well for symmetric distributions</li>
<li><strong>“basic”</strong>: Similar to percentile but adjusts for
bias, more conservative</li>
<li><strong>“stud”</strong> (Studentized): Uses the standard error of
each bootstrap sample, more accurate for skewed distributions</li>
</ul>
</div>
</div>
<div id="hypothesis-testing-with-ses_calc" class="section level2">
<h2>Hypothesis Testing with <code>ses_calc</code></h2>
<p>As of v0.9.0, <code>ses_calc</code> supports hypothesis testing
directly on the effect size scale by setting the
<code>alternative</code> argument. This allows you to test whether a
non-parametric effect size differs from a specified value, or whether it
falls within equivalence bounds — without needing the raw-scale
equivalence bounds required by <code>wilcox_TOST</code>.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" tabindex="-1"></a><span class="co"># Two-sided test: does the rank-biserial differ from 0?</span></span>
<span id="cb81-2"><a href="#cb81-2" tabindex="-1"></a><span class="fu">ses_calc</span>(<span class="at">x =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">1</span>],</span>
<span id="cb81-3"><a href="#cb81-3" tabindex="-1"></a>         <span class="at">y =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">2</span>],</span>
<span id="cb81-4"><a href="#cb81-4" tabindex="-1"></a>         <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb81-5"><a href="#cb81-5" tabindex="-1"></a>         <span class="at">ses =</span> <span class="st">&quot;rb&quot;</span>,</span>
<span id="cb81-6"><a href="#cb81-6" tabindex="-1"></a>         <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Paired Sample Rank-Biserial Correlation test
## 
## data:  sleep$extra[sleep$group == 1] and sleep$extra[sleep$group == 2]
## z = 0.2255, p-value = 0.8216
## alternative hypothesis: true Rank-Biserial Correlation is not equal to 0
## 95 percent confidence interval:
##  -1  1
## sample estimates:
## Rank-Biserial Correlation 
##                 0.9818182</code></pre>
<div id="equivalence-testing-on-the-effect-size-scale" class="section level3">
<h3>Equivalence Testing on the Effect Size Scale</h3>
<p>One advantage of testing directly on the effect size scale is that
equivalence bounds have a more intuitive interpretation. Rather than
specifying bounds in raw units (which depends on the location-shift
assumption), you can specify bounds directly in terms of the effect
size:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" tabindex="-1"></a><span class="co"># Equivalence test: is the rank-biserial within [-0.3, 0.3]?</span></span>
<span id="cb83-2"><a href="#cb83-2" tabindex="-1"></a><span class="fu">ses_calc</span>(<span class="at">x =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">1</span>],</span>
<span id="cb83-3"><a href="#cb83-3" tabindex="-1"></a>         <span class="at">y =</span> sleep<span class="sc">$</span>extra[sleep<span class="sc">$</span>group <span class="sc">==</span> <span class="dv">2</span>],</span>
<span id="cb83-4"><a href="#cb83-4" tabindex="-1"></a>         <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb83-5"><a href="#cb83-5" tabindex="-1"></a>         <span class="at">ses =</span> <span class="st">&quot;rb&quot;</span>,</span>
<span id="cb83-6"><a href="#cb83-6" tabindex="-1"></a>         <span class="at">alternative =</span> <span class="st">&quot;equivalence&quot;</span>,</span>
<span id="cb83-7"><a href="#cb83-7" tabindex="-1"></a>         <span class="at">null.value =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>))</span></code></pre></div>
<pre><code>## Hypothesis test conducted on log-odds scale. Bounds [-0.3, 0.3] on rb scale correspond to [-0.619, 0.619] on log-odds scale.</code></pre>
<pre><code>## 
##  Paired Sample Rank-Biserial Correlation test
## 
## data:  sleep$extra[sleep$group == 1] and sleep$extra[sleep$group == 2]
## z = 0.19574, p-value = 0.5776
## alternative hypothesis: equivalence
## null values:
## lower bound upper bound 
##        -0.3         0.3 
## 90 percent confidence interval:
##  -1  1
## sample estimates:
## Rank-Biserial Correlation 
##                 0.9818182</code></pre>
<p>When using <code>ses_calc</code> for hypothesis testing, the
<code>se_method</code> argument (described in the <a href="#confidence-interval-methods">Confidence Interval Methods</a>
section above) also controls how test statistics are computed. The
default Agresti method conducts tests on the log-odds scale, while the
Fisher method uses z-transformation. See above for details.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" tabindex="-1"></a><span class="co"># Using the Agresti method (default) with WMW odds</span></span>
<span id="cb86-2"><a href="#cb86-2" tabindex="-1"></a><span class="fu">ses_calc</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb86-3"><a href="#cb86-3" tabindex="-1"></a>         <span class="at">data =</span> sleep,</span>
<span id="cb86-4"><a href="#cb86-4" tabindex="-1"></a>         <span class="at">ses =</span> <span class="st">&quot;odds&quot;</span>,</span>
<span id="cb86-5"><a href="#cb86-5" tabindex="-1"></a>         <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Two Sample WMW Odds test
## 
## data:  extra by group
## z = -1.8794, p-value = 0.06019
## alternative hypothesis: true WMW Odds is not equal to 1
## 95 percent confidence interval:
##  0.1118928 1.0470460
## sample estimates:
##  WMW Odds 
## 0.3422819</code></pre>
</div>
</div>
<div id="permutation-based-effect-size-testing-with-perm_ses_test" class="section level2">
<h2>Permutation-Based Effect Size Testing with
<code>perm_ses_test</code></h2>
<p>When asymptotic approximations may be unreliable — particularly with
small samples — <code>perm_ses_test</code> provides distribution-free
inference for the same non-parametric effect sizes. Rather than relying
on normal approximations, it constructs the null distribution of the
effect size through permutation.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" tabindex="-1"></a><span class="co"># Permutation test of rank-biserial correlation</span></span>
<span id="cb88-2"><a href="#cb88-2" tabindex="-1"></a><span class="fu">perm_ses_test</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb88-3"><a href="#cb88-3" tabindex="-1"></a>              <span class="at">data =</span> sleep,</span>
<span id="cb88-4"><a href="#cb88-4" tabindex="-1"></a>              <span class="at">ses =</span> <span class="st">&quot;rb&quot;</span>,</span>
<span id="cb88-5"><a href="#cb88-5" tabindex="-1"></a>              <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,</span>
<span id="cb88-6"><a href="#cb88-6" tabindex="-1"></a>              <span class="at">R =</span> <span class="dv">1999</span>)</span></code></pre></div>
<pre><code>## 
##  Randomization Permutation Rank-Biserial Correlation Test (Two-Sample)
## 
## data:  extra by group
## observed = -0.49, R = 1999, p-value = 0.069
## alternative hypothesis: true Rank-Biserial Correlation is not equal to 0
## 95 percent confidence interval:
##  -0.51  0.53
## sample estimates:
## Rank-Biserial Correlation 
##                     -0.49</code></pre>
<div id="equivalence-testing-with-permutation" class="section level3">
<h3>Equivalence Testing with Permutation</h3>
<p>The function supports equivalence testing using the
intersection-union nonparametric combination (IU-NPC) approach <span class="citation">(Arboretti et al. 2021)</span>:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" tabindex="-1"></a><span class="co"># Permutation-based equivalence test on the concordance scale</span></span>
<span id="cb90-2"><a href="#cb90-2" tabindex="-1"></a><span class="fu">perm_ses_test</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb90-3"><a href="#cb90-3" tabindex="-1"></a>              <span class="at">data =</span> sleep,</span>
<span id="cb90-4"><a href="#cb90-4" tabindex="-1"></a>              <span class="at">ses =</span> <span class="st">&quot;cstat&quot;</span>,</span>
<span id="cb90-5"><a href="#cb90-5" tabindex="-1"></a>              <span class="at">alternative =</span> <span class="st">&quot;equivalence&quot;</span>,</span>
<span id="cb90-6"><a href="#cb90-6" tabindex="-1"></a>              <span class="at">mu =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>),</span>
<span id="cb90-7"><a href="#cb90-7" tabindex="-1"></a>              <span class="at">R =</span> <span class="dv">1999</span>)</span></code></pre></div>
<pre><code>## 
##  Randomization Permutation Concordance Test (Two-Sample)
## 
## data:  extra by group
## observed = 0.255, R = 1999, p-value = 0.6245
## alternative hypothesis: equivalence
## null values:
## lower bound upper bound 
##         0.3         0.7 
## 90 percent confidence interval:
##  0.2895 0.7100
## sample estimates:
## Concordance 
##       0.255</code></pre>
</div>
<div id="when-to-use-perm_ses_test-vs.-ses_calc" class="section level3">
<h3>When to Use <code>perm_ses_test</code>
vs. <code>ses_calc</code></h3>
<table>
<colgroup>
<col width="24%" />
<col width="29%" />
<col width="45%" />
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th><code>ses_calc</code></th>
<th><code>perm_ses_test</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Inference method</td>
<td>Asymptotic (normal approximation)</td>
<td>Distribution-free (permutation)</td>
</tr>
<tr class="even">
<td>P-values</td>
<td>Based on z-statistic</td>
<td>Exact or randomization-based</td>
</tr>
<tr class="odd">
<td>Best for</td>
<td>Moderate to large samples</td>
<td>Small samples</td>
</tr>
<tr class="even">
<td>Speed</td>
<td>Fast (closed-form)</td>
<td>Slower (requires permutations)</td>
</tr>
<tr class="odd">
<td>Exact p-values</td>
<td>No</td>
<td>Yes (when all permutations enumerated)</td>
</tr>
</tbody>
</table>
<p>For small samples where exact permutations are feasible,
<code>perm_ses_test</code> is generally preferred. For larger samples,
<code>ses_calc</code> with the Agresti method provides reliable
inference with minimal computational cost.</p>
</div>
</div>
</div>
<div id="summary-comparison-of-robust-tost-methods" class="section level1">
<h1>Summary Comparison of Robust TOST Methods</h1>
<table>
<colgroup>
<col width="15%" />
<col width="29%" />
<col width="25%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Key Advantages</th>
<th>Limitations</th>
<th>Best Use Cases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Wilcoxon-Mann-Whitney</strong></td>
<td>Simple, widely accepted</td>
<td>Ambiguous hypothesis; not about means or medians (see caveats
above)</td>
<td>Ordinal data; legacy analyses</td>
</tr>
<tr class="even">
<td><strong>Brunner-Munzel</strong></td>
<td>Clear interpretation, robust to heteroscedasticity</td>
<td>Computationally intensive with permutation</td>
<td>Stochastic superiority/dominance</td>
</tr>
<tr class="odd">
<td><strong>Hodges-Lehmann</strong></td>
<td>Robust location, explicit estimand</td>
<td>Requires location-shift assumption for full interpretation</td>
<td>Robust location shift testing</td>
</tr>
<tr class="even">
<td><strong>Permutation t-test</strong></td>
<td>Exact p-values (small samples), supports trimmed means</td>
<td>Computationally intensive for large samples</td>
<td>Mean differences with small samples</td>
</tr>
<tr class="odd">
<td><strong>Bootstrap t-test</strong></td>
<td>Flexible, visualization of effect distributions</td>
<td>Results vary between runs</td>
<td>Mean differences with moderate samples</td>
</tr>
<tr class="even">
<td><strong>Log-Transformed</strong></td>
<td>Focuses on relative differences, stabilizes variance</td>
<td>Requires positive data</td>
<td>Bioequivalence, ratio comparisons</td>
</tr>
<tr class="odd">
<td><strong>SES calc / Perm SES test</strong></td>
<td>Tests directly on effect size scale</td>
<td>Requires large samples (asymptotic) or many permutations</td>
<td>Non-parametric effect size testing</td>
</tr>
</tbody>
</table>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>The robust TOST procedures provided in the TOSTER package offer
reliable alternatives to standard t-test based equivalence testing when
data violate typical assumptions. By selecting the appropriate robust
method for your specific data characteristics and research question, you
can ensure more valid statistical inferences about equivalence or
minimal effects.</p>
<p>Remember that no single method is universally superior - the choice
depends on your data structure, sample size, and specific research
question. When in doubt, running multiple approaches and comparing
results can provide valuable insights into the robustness of your
conclusions.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-agresti" class="csl-entry">
Agresti, Alan. 1980. <span>“Generalized Odds Ratios for Ordinal
Data.”</span> <em>Biometrics</em>, 59–67. <a href="https://doi.org/10.2307/2530495">https://doi.org/10.2307/2530495</a>.
</div>
<div id="ref-arboretti2021" class="csl-entry">
Arboretti, Rosa, Stefano Bonnini, Livio Corain, and Luigi Salmaso. 2021.
<span>“Nonparametric Combination Tests for Comparing Two Treatments with
Respect to a Non-Inferiority Margin Expressed as a Ratio.”</span>
<em>Statistics in Medicine</em> 40 (18): 4078–93. <a href="https://doi.org/10.1002/sim.9015">https://doi.org/10.1002/sim.9015</a>.
</div>
<div id="ref-brunner2000" class="csl-entry">
Brunner, Edgar, and Ullrich Munzel. 2000. <span>“The Nonparametric
Behrens-Fisher Problem: Asymptotic Theory and a Small-Sample
Approximation.”</span> <em>Biometrical Journal</em> 42 (1): 17–25. <a href="https://doi.org/10.1002/(sici)1521-4036(200001)42:1%3C17::aid-bimj17%3E3.0.co;2-u">https://doi.org/10.1002/(sici)1521-4036(200001)42:1&lt;17::aid-bimj17&gt;3.0.co;2-u</a>.
</div>
<div id="ref-chung2013" class="csl-entry">
Chung, EunYi, and Joseph P. Romano. 2013. <span>“Exact and
Asymptotically Robust Permutation Tests.”</span> <em>The Annals of
Statistics</em> 41 (2). <a href="https://doi.org/10.1214/13-aos1090">https://doi.org/10.1214/13-aos1090</a>.
</div>
<div id="ref-divine2018" class="csl-entry">
Divine, George W, H James Norton, Anna E Barón, and Elizabeth
Juarez-Colunga. 2018. <span>“The Wilcoxon–Mann–Whitney Procedure Fails
as a Test of Medians.”</span> <em>The American Statistician</em> 72 (3):
278–86. <a href="https://doi.org/10.1080/00031305.2017.1305291">https://doi.org/10.1080/00031305.2017.1305291</a>.
</div>
<div id="ref-efron93" class="csl-entry">
Efron, Bradley, and Robert J. Tibshirani. 1993. <em>An Introduction to
the Bootstrap</em>. Monographs on Statistics and Applied Probability 57.
Boca Raton, Florida, USA: Chapman &amp; Hall/CRC.
</div>
<div id="ref-fried2011" class="csl-entry">
Fried, Roland, and Herold Dehling. 2011. <span>“Robust Nonparametric
Tests for the Two-Sample Location Problem.”</span> <em>Stat. Methods
Appt.</em> 20 (4): 409–22.
</div>
<div id="ref-he2022" class="csl-entry">
He, Y, Y Deng, C You, and X H Zhou. 2022. <span>“Equivalence Tests for
Ratio of Means in Bioequivalence Studies Under Crossover
Designs.”</span> <em>Statistical Methods in Medical Research</em>,
09622802221093721. <a href="https://doi.org/10.1177/09622802221093721">https://doi.org/10.1177/09622802221093721</a>.
</div>
<div id="ref-hodges1963" class="csl-entry">
Hodges, Joseph L, and Erich L Lehmann. 1963. <span>“Estimates of
Location Based on Rank Tests.”</span> <em>The Annals of Mathematical
Statistics</em> 34 (2): 598–611. <a href="https://doi.org/10.1214/aoms/1177704172">https://doi.org/10.1214/aoms/1177704172</a>.
</div>
<div id="ref-janssen1997" class="csl-entry">
Janssen, Arnold. 1997. <span>“Studentized Permutation Tests for
Non-i.i.d. Hypotheses and the Generalized Behrens-Fisher
Problem.”</span> <em>Statistics and Probability Letters</em> 36 (1):
9–21. <a href="https://doi.org/10.1016/s0167-7152(97)00043-6">https://doi.org/10.1016/s0167-7152(97)00043-6</a>.
</div>
<div id="ref-karch2021" class="csl-entry">
Karch, Julian D. 2021. <span>“Psychologists Should Use Brunner-Munzel’s
Instead of Mann-Whitney’s Test as the Default Nonparametric
Procedure.”</span> <em>Advances in Methods and Practices in
Psychological Science</em> 4 (2): 251524592199960. <a href="https://doi.org/10.1177/2515245921999602">https://doi.org/10.1177/2515245921999602</a>.
</div>
<div id="ref-Kerby_2014" class="csl-entry">
Kerby, Dave S. 2014. <span>“The Simple Difference Formula: An Approach
to Teaching Nonparametric Correlation.”</span> <em>Comprehensive
Psychology</em> 3 (January): 11.IT.3.1. <a href="https://doi.org/10.2466/11.it.3.1">https://doi.org/10.2466/11.it.3.1</a>.
</div>
<div id="ref-munzel2003" class="csl-entry">
Munzel, Ullrich, and Dieter Hauschke. 2003. <span>“A Nonparametric Test
for Proving Noninferiority in Clinical Trials with Ordered Categorical
Data.”</span> <em>Pharm. Stat.</em> 2 (1): 31–37.
</div>
<div id="ref-neubert2007" class="csl-entry">
Neubert, Karin, and Edgar Brunner. 2007. <span>“A Studentized
Permutation Test for the Non-Parametric Behrens<span></span>fisher
Problem.”</span> <em>Computational Statistics and Data Analysis</em> 51
(10): 5192–5204. <a href="https://doi.org/10.1016/j.csda.2006.05.024">https://doi.org/10.1016/j.csda.2006.05.024</a>.
</div>
<div id="ref-wmwodds" class="csl-entry">
O’Brien, Ralph G, and John Castelloe. 2006. <span>“Exploiting the Link
Between the Wilcoxon-Mann-Whitney Test and a Simple Odds
Statistic,”</span> 209–31.
</div>
<div id="ref-phipson2010" class="csl-entry">
Phipson, Belinda, and Gordon K Smyth. 2010. <span>“Permutation p-Values
Should Never Be Zero: Calculating Exact p-Values When Permutations Are
Randomly Drawn.”</span> <em>Statistical Applications in Genetics and
Molecular Biology</em> 9 (1). <a href="https://doi.org/10.2202/1544-6115.1585">https://doi.org/10.2202/1544-6115.1585</a>.
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>I would like to note that I think the statistical
properties of the WMW tests are sound, and Frank Harrell has written <a href="https://www.fharrell.com/post/po/">many</a> <a href="https://www.fharrell.com/post/wpo/">blogposts</a> outlining their
sound application in biomedicine.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>This means the relative effect will <em>not</em> match
the concordance probability provided by <code>ses_calc</code>.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Food and Drug Administration (2014). Bioavailability and
Bioequivalence Studies Submitted in NDAs or INDs — General
Considerations.Center for Drug Evaluation and Research. Docket:
FDA-2014-D-0204<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>The results from <code>ses_calc</code> and
<code>boot_ses_calc</code> can differ substantially because the
bootstrap CI method is typically more conservative than the asymptotic
method. This difference is more apparent with extremely small samples
like that in the <code>sleep</code> dataset.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Directly inspired by this blog post from Professor Frank
Harrell <a href="https://hbiostat.org/blog/post/wpo/" class="uri">https://hbiostat.org/blog/post/wpo/</a><a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>As noted by my frequent collaborator this name is quite
weird since it is not a ratio of odds… but simply an odds!<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Aaron R. Caldwell" />

<meta name="date" content="2025-03-25" />

<title>Robust TOST Procedures</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Robust TOST Procedures</h1>
<h4 class="author">Aaron R. Caldwell</h4>
<h4 class="date">2025-03-25</h4>


<div id="TOC">
<ul>
<li><a href="#introduction-to-robust-tost-methods" id="toc-introduction-to-robust-tost-methods">Introduction to Robust TOST
Methods</a>
<ul>
<li><a href="#when-to-use-robust-tost-methods" id="toc-when-to-use-robust-tost-methods">When to Use Robust TOST
Methods</a></li>
</ul></li>
<li><a href="#wilcoxon-tost" id="toc-wilcoxon-tost">Wilcoxon TOST</a>
<ul>
<li><a href="#key-features-and-usage" id="toc-key-features-and-usage">Key Features and Usage</a>
<ul>
<li><a href="#interpreting-the-results" id="toc-interpreting-the-results">Interpreting the Results</a></li>
</ul></li>
<li><a href="#rank-biserial-correlation" id="toc-rank-biserial-correlation">Rank-Biserial Correlation</a></li>
<li><a href="#confidence-intervals" id="toc-confidence-intervals">Confidence Intervals</a></li>
<li><a href="#conversion-to-other-effect-sizes" id="toc-conversion-to-other-effect-sizes">Conversion to other effect
sizes</a>
<ul>
<li><a href="#guidelines-for-selecting-effect-size-measures" id="toc-guidelines-for-selecting-effect-size-measures">Guidelines for
Selecting Effect Size Measures</a></li>
</ul></li>
</ul></li>
<li><a href="#brunner-munzel" id="toc-brunner-munzel">Brunner-Munzel</a>
<ul>
<li><a href="#overview-and-advantages" id="toc-overview-and-advantages">Overview and Advantages</a></li>
<li><a href="#basics-of-the-calculative-approach" id="toc-basics-of-the-calculative-approach">Basics of the Calculative
Approach</a></li>
<li><a href="#example" id="toc-example">Example</a>
<ul>
<li><a href="#interpreting-brunner-munzel-results" id="toc-interpreting-brunner-munzel-results">Interpreting Brunner-Munzel
Results</a></li>
<li><a href="#when-to-use-permutation" id="toc-when-to-use-permutation">When to Use Permutation</a></li>
</ul></li>
</ul></li>
<li><a href="#bootstrap-tost" id="toc-bootstrap-tost">Bootstrap TOST</a>
<ul>
<li><a href="#advantages-of-bootstrapping" id="toc-advantages-of-bootstrapping">Advantages of
Bootstrapping</a></li>
<li><a href="#two-sample-algorithm" id="toc-two-sample-algorithm">Two
Sample Algorithm</a></li>
<li><a href="#choosing-the-number-of-bootstrap-replications" id="toc-choosing-the-number-of-bootstrap-replications">Choosing the
Number of Bootstrap Replications</a></li>
<li><a href="#example-1" id="toc-example-1">Example</a>
<ul>
<li><a href="#interpreting-bootstrap-tost-results" id="toc-interpreting-bootstrap-tost-results">Interpreting Bootstrap TOST
Results</a></li>
</ul></li>
</ul></li>
<li><a href="#ratio-of-difference-log-transformed" id="toc-ratio-of-difference-log-transformed">Ratio of Difference (Log
Transformed)</a>
<ul>
<li><a href="#why-use-the-natural-log-transformation" id="toc-why-use-the-natural-log-transformation">Why Use The Natural Log
Transformation?</a></li>
<li><a href="#applications-beyond-bioequivalence" id="toc-applications-beyond-bioequivalence">Applications Beyond
Bioequivalence</a></li>
<li><a href="#log_tost" id="toc-log_tost">log_TOST</a>
<ul>
<li><a href="#interpreting-the-means-ratio" id="toc-interpreting-the-means-ratio">Interpreting the Means
Ratio</a></li>
</ul></li>
<li><a href="#bootstrap-log" id="toc-bootstrap-log">Bootstrap +
Log</a></li>
</ul></li>
<li><a href="#just-estimate-an-effect-size" id="toc-just-estimate-an-effect-size">Just Estimate an Effect Size</a>
<ul>
<li><a href="#choosing-between-different-bootstrap-ci-methods" id="toc-choosing-between-different-bootstrap-ci-methods">Choosing
Between Different Bootstrap CI Methods</a></li>
</ul></li>
<li><a href="#summary-comparison-of-robust-tost-methods" id="toc-summary-comparison-of-robust-tost-methods">Summary Comparison of
Robust TOST Methods</a></li>
<li><a href="#conclusion" id="toc-conclusion">Conclusion</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<div id="introduction-to-robust-tost-methods" class="section level1">
<h1>Introduction to Robust TOST Methods</h1>
<p>The Two One-Sided Tests (TOST) procedure is a statistical approach
used to test for equivalence between groups or conditions. Unlike
traditional null hypothesis significance testing (NHST) which aims to
detect differences, TOST is designed to statistically demonstrate
similarity or equivalence within predefined bounds.</p>
<p>While the standard <code>t_TOST</code> function in TOSTER provides a
parametric approach to equivalence testing, it relies on assumptions of
normality and homogeneity of variance. In real-world data analysis,
these assumptions are often violated, necessitating more robust
alternatives. This vignette introduces several robust TOST methods
available in the TOSTER package that maintain their validity under a
wider range of data conditions.</p>
<div id="when-to-use-robust-tost-methods" class="section level2">
<h2>When to Use Robust TOST Methods</h2>
<p>Consider using the robust alternatives to <code>t_TOST</code>
when:</p>
<ul>
<li>Your data shows notable departures from normality (e.g., skewed
distributions, heavy tails)</li>
<li>Potential outliers are a concern</li>
<li>Sample sizes are small or unequal</li>
<li>You have concerns about violating the assumptions of parametric
tests</li>
<li>You want to confirm parametric test results with complementary
nonparametric approaches</li>
</ul>
<p>The following table provides a quick overview of the robust methods
covered in this vignette:</p>
<table>
<colgroup>
<col width="14%" />
<col width="18%" />
<col width="38%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Function</th>
<th>Key Characteristics</th>
<th>Best Used When</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Wilcoxon TOST</td>
<td><code>wilcox_TOST()</code></td>
<td>Rank-based, nonparametric</td>
<td>Data is ordinal or non-normal</td>
</tr>
<tr class="even">
<td>Brunner-Munzel</td>
<td><code>brunner_munzel()</code> with <code>simple_htest()</code></td>
<td>Probability-based, robust to heteroscedasticity</td>
<td>Distribution shapes differ between groups</td>
</tr>
<tr class="odd">
<td>Bootstrap TOST</td>
<td><code>boot_t_TOST()</code></td>
<td>Resampling-based, requires fewer assumptions</td>
<td>Sample size is small or distribution is unknown</td>
</tr>
<tr class="even">
<td>Log-Transformed TOST</td>
<td><code>log_TOST()</code></td>
<td>Ratio-based, for multiplicative comparisons</td>
<td>Comparing relative differences (e.g., bioequivalence)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="wilcoxon-tost" class="section level1">
<h1>Wilcoxon TOST</h1>
<p>The Wilcoxon group of tests (includes Mann-Whitney U-test) provide a
non-parametric test of differences between groups, or within samples,
based on ranks. This provides a test of location shift, which is a fancy
way of saying differences in the center of the distribution (i.e., in
parametric tests the location is mean). With TOST, there are two
separate tests of directional location shift to determine if the
location shift is within (equivalence) or outside (minimal effect). The
exact calculations can be explored via the documentation of the
<code>wilcox.test</code> function.</p>
<div id="key-features-and-usage" class="section level2">
<h2>Key Features and Usage</h2>
<p>TOSTER’s version is the <code>wilcox_TOST</code> function. Overall,
this function operates extremely similar to the <code>t_TOST</code>
function. However, the standardized mean difference (SMD) is
<em>not</em> calculated. Instead the rank-biserial correlation is
calculated for <em>all</em> types of comparisons (e.g., two sample, one
sample, and paired samples). Also, there is no plotting capability at
this time for the output of this function.</p>
<p>The <code>wilcox_TOST</code> function is particularly useful
when:</p>
<ul>
<li>You’re working with ordinal data</li>
<li>You’re concerned about outliers influencing your results</li>
<li>You need a test that makes minimal assumptions about the underlying
distributions</li>
</ul>
<p>As an example, we can use the sleep data to make a non-parametric
comparison of equivalence.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&#39;sleep&#39;</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(TOSTER)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>test1 <span class="ot">=</span> <span class="fu">wilcox_TOST</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>                      <span class="at">paired =</span> <span class="cn">FALSE</span>,</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>)</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="fu">print</span>(test1)</span></code></pre></div>
<pre><code>## 
## Wilcoxon rank sum test with continuity correction
## 
## The equivalence test was non-significant W = 20.000, p = 8.94e-01
## The null hypothesis test was non-significant W = 25.500, p = 6.93e-02
## NHST: don&#39;t reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##            Test Statistic p.value
## NHST                 25.5   0.069
## TOST Lower           34.0   0.894
## TOST Upper           20.0   0.013
## 
## Effect Sizes 
##                           Estimate               C.I. Conf. Level
## Median of Differences       -1.346       [-3.4, -0.1]         0.9
## Rank-Biserial Correlation   -0.490 [-0.7493, -0.1005]         0.9</code></pre>
<div id="interpreting-the-results" class="section level3">
<h3>Interpreting the Results</h3>
<p>When interpreting the output of <code>wilcox_TOST</code>, pay
attention to:</p>
<ol style="list-style-type: decimal">
<li>The p-values for both one-sided tests (<code>p1</code> and
<code>p2</code>)</li>
<li>The equivalence test p-value (<code>TOSTp</code>), which should be
&lt; alpha to claim equivalence</li>
<li>The rank-biserial correlation (<code>rb</code>) and its confidence
interval</li>
</ol>
<p>A statistically significant equivalence test (p &lt; alpha) indicates
that the observed effect is statistically within your specified
equivalence bounds. The rank-biserial correlation provides a measure of
effect size, with values ranging from -1 to 1:</p>
<ul>
<li>Values near 0 indicate negligible association</li>
<li>Values around ±0.3 indicate a small effect</li>
<li>Values around ±0.5 indicate a moderate effect</li>
<li>Values around ±0.7 or greater indicate a large effect</li>
</ul>
</div>
</div>
<div id="rank-biserial-correlation" class="section level2">
<h2>Rank-Biserial Correlation</h2>
<p>The standardized effect size reported for the
<code>wilcox_TOST</code> procedure is the rank-biserial correlation.
This is a fairly intuitive measure of effect size which has the same
interpretation of the common language effect size <span class="citation">(Kerby 2014)</span>. However, instead of assuming
normality and equal variances, the rank-biserial correlation calculates
the number of favorable (positive) and unfavorable (negative) pairs
based on their respective ranks.</p>
<p>For the two sample case, the correlation is calculated as the
proportion of favorable pairs minus the unfavorable pairs.</p>
<p><span class="math display">\[
r_{biserial} = f_{pairs} - u_{pairs}
\]</span></p>
<p>Where: - <span class="math inline">\(f_{pairs}\)</span> is the
proportion of favorable pairs - <span class="math inline">\(u_{pairs}\)</span> is the proportion of
unfavorable pairs</p>
<p>For the one sample or paired samples cases, the correlation is
calculated with ties (values equal to zero) not being dropped. This
provides a <em>conservative</em> estimate of the rank biserial
correlation.</p>
<p>It is calculated in the following steps wherein <span class="math inline">\(z\)</span> represents the values or difference
between paired observations:</p>
<ol style="list-style-type: decimal">
<li>Calculate signed ranks:</li>
</ol>
<p><span class="math display">\[
r_j = -1 \cdot sign(z_j) \cdot rank(|z_j|)
\]</span></p>
<p>Where: - <span class="math inline">\(r_j\)</span> is the signed rank
for observation <span class="math inline">\(j\)</span> - <span class="math inline">\(sign(z_j)\)</span> is the sign of observation
<span class="math inline">\(z_j\)</span> (+1 or -1) - <span class="math inline">\(rank(|z_j|)\)</span> is the rank of the absolute
value of observation <span class="math inline">\(z_j\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Calculate the positive and negative sums:</li>
</ol>
<p><span class="math display">\[
    R_{+} = \sum_{1\le i \le n, \space z_i &gt; 0}r_j
\]</span></p>
<p><span class="math display">\[
    R_{-} = \sum_{1\le i \le n, \space z_i &lt; 0}r_j
\]</span></p>
<p>Where: - <span class="math inline">\(R_{+}\)</span> is the sum of
ranks for positive observations - <span class="math inline">\(R_{-}\)</span> is the sum of ranks for negative
observations</p>
<ol start="3" style="list-style-type: decimal">
<li>Determine the smaller of the two rank sums:</li>
</ol>
<p><span class="math display">\[
T = min(R_{+}, \space R_{-})
\]</span></p>
<p><span class="math display">\[
S = \begin{cases} -4 &amp; R_{+} \ge R_{-} \\ 4 &amp; R_{+} &lt; R_{-}
\end{cases}
\]</span></p>
<p>Where: - <span class="math inline">\(T\)</span> is the smaller of the
two rank sums - <span class="math inline">\(S\)</span> is a sign factor
based on which rank sum is smaller</p>
<ol start="4" style="list-style-type: decimal">
<li>Calculate rank-biserial correlation:</li>
</ol>
<p><span class="math display">\[
r_{biserial} = S \cdot | \frac{\frac{T - \frac{(R_{+} +
R_{-})}{2}}{n}}{n + 1} |
\]</span></p>
<p>Where: - <span class="math inline">\(n\)</span> is the number of
observations (or pairs) - The final value ranges from -1 to 1</p>
</div>
<div id="confidence-intervals" class="section level2">
<h2>Confidence Intervals</h2>
<p>The Fisher approximation is used to calculate the confidence
intervals.</p>
<p>For paired samples, or one sample, the standard error is calculated
as the following:</p>
<p><span class="math display">\[
SE_r = \sqrt{ \frac {(2 \cdot nd^3 + 3 \cdot nd^2 + nd) / 6} {(nd^2 +
nd) / 2} }
\]</span></p>
<p>wherein, nd represents the total number of observations (or
pairs).</p>
<p>For independent samples, the standard error is calculated as the
following:</p>
<p><span class="math display">\[
SE_r = \sqrt{\frac {(n1 + n2 + 1)} { (3 \cdot n1 \cdot n2)}}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(n1\)</span> and <span class="math inline">\(n2\)</span> are the sample sizes of the two
groups</li>
</ul>
<p>The confidence intervals can then be calculated by transforming the
estimate.</p>
<p><span class="math display">\[
r_z = atanh(r_{biserial})
\]</span></p>
<p>Then the confidence interval can be calculated and back
transformed.</p>
<p><span class="math display">\[
r_{CI} = tanh(r_z  \pm  Z_{(1 - \alpha / 2)} \cdot SE_r)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(Z_{(1 - \alpha / 2)}\)</span> is the
critical value from the standard normal distribution</li>
<li><span class="math inline">\(\alpha\)</span> is the significance
level (typically 0.05)</li>
</ul>
</div>
<div id="conversion-to-other-effect-sizes" class="section level2">
<h2>Conversion to other effect sizes</h2>
<p>Two other effect sizes can be calculated for non-parametric tests.
First, there is the concordance probability, which is also known as the
c-statistic, c-index, or probability of superiority<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. The c-statistic is
converted from the correlation using the following formula:</p>
<p><span class="math display">\[
c = \frac{(r_{biserial} + 1)}{2}
\]</span></p>
<p>The c-statistic can be interpreted as the probability that a randomly
selected observation from one group will be greater than a randomly
selected observation from another group. A value of 0.5 indicates no
difference between groups, while values approaching 1 indicate perfect
separation between groups.</p>
<p>The Wilcoxon-Mann-Whitney odds <span class="citation">(O’Brien and
Castelloe 2006)</span>, also known as the “Generalized Odds Ratio” <span class="citation">(Agresti 1980)</span>, is calculated by converting the
c-statistic using the following formula:</p>
<p><span class="math display">\[
WMW_{odds} = e^{logit(c)}
\]</span></p>
<p>Where <span class="math inline">\(logit(c) =
\ln\frac{c}{1-c}\)</span></p>
<p>The WMW odds can be interpreted similarly to a traditional odds
ratio, representing the odds that an observation from one group is
greater than an observation from another group.</p>
<p>Either effect size is available by simply modifying the
<code>ses</code> argument for the <code>wilcox_TOST</code> function.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Rank biserial</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="fu">wilcox_TOST</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>                      <span class="at">paired =</span> <span class="cn">FALSE</span>,</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>                      <span class="at">ses =</span> <span class="st">&quot;r&quot;</span>,</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>)</span></code></pre></div>
<pre><code>## 
## Wilcoxon rank sum test with continuity correction
## 
## The equivalence test was non-significant W = 20.000, p = 8.94e-01
## The null hypothesis test was non-significant W = 25.500, p = 6.93e-02
## NHST: don&#39;t reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##            Test Statistic p.value
## NHST                 25.5   0.069
## TOST Lower           34.0   0.894
## TOST Upper           20.0   0.013
## 
## Effect Sizes 
##                           Estimate               C.I. Conf. Level
## Median of Differences       -1.346       [-3.4, -0.1]         0.9
## Rank-Biserial Correlation   -0.490 [-0.7493, -0.1005]         0.9</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Odds</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="fu">wilcox_TOST</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>                      <span class="at">paired =</span> <span class="cn">FALSE</span>,</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>                      <span class="at">ses =</span> <span class="st">&quot;o&quot;</span>,</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>)</span></code></pre></div>
<pre><code>## 
## Wilcoxon rank sum test with continuity correction
## 
## The equivalence test was non-significant W = 20.000, p = 8.94e-01
## The null hypothesis test was non-significant W = 25.500, p = 6.93e-02
## NHST: don&#39;t reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##            Test Statistic p.value
## NHST                 25.5   0.069
## TOST Lower           34.0   0.894
## TOST Upper           20.0   0.013
## 
## Effect Sizes 
##                       Estimate             C.I. Conf. Level
## Median of Differences  -1.3464     [-3.4, -0.1]         0.9
## WMW Odds                0.3423 [0.1433, 0.8173]         0.9</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Concordance</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="fu">wilcox_TOST</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>                      <span class="at">paired =</span> <span class="cn">FALSE</span>,</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>                      <span class="at">ses =</span> <span class="st">&quot;c&quot;</span>,</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>)</span></code></pre></div>
<pre><code>## 
## Wilcoxon rank sum test with continuity correction
## 
## The equivalence test was non-significant W = 20.000, p = 8.94e-01
## The null hypothesis test was non-significant W = 25.500, p = 6.93e-02
## NHST: don&#39;t reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##            Test Statistic p.value
## NHST                 25.5   0.069
## TOST Lower           34.0   0.894
## TOST Upper           20.0   0.013
## 
## Effect Sizes 
##                       Estimate             C.I. Conf. Level
## Median of Differences   -1.346     [-3.4, -0.1]         0.9
## Concordance              0.255 [0.1254, 0.4497]         0.9</code></pre>
<div id="guidelines-for-selecting-effect-size-measures" class="section level3">
<h3>Guidelines for Selecting Effect Size Measures</h3>
<ul>
<li><strong>Rank-biserial correlation (<code>&quot;r&quot;</code>)</strong> is
useful when you want a correlation-like measure that’s easily
interpretable and comparable to other correlation coefficients.</li>
<li><strong>Concordance probability (<code>&quot;c&quot;</code>)</strong> is
beneficial when you want to express the effect in terms of probability,
making it accessible to non-statisticians.</li>
<li><strong>WMW odds (<code>&quot;o&quot;</code>)</strong> is helpful when you
want to express the effect in terms familiar to those who work with odds
ratios in logistic regression or epidemiology.</li>
</ul>
</div>
</div>
</div>
<div id="brunner-munzel" class="section level1">
<h1>Brunner-Munzel</h1>
<p>As <span class="citation">Karch (2021)</span> explained, there are
some reasons to dislike the WMW family of tests as the non-parametric
alternative to the t-test. Regardless of the underlying statistical
arguments<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>, it can be argued that the interpretation
of the WMW tests, especially when involving equivalence testing, is a
tad difficult. Some may want a non-parametric alternative to the WMW
test, and the Brunner-Munzel test(s) may be a useful option.</p>
<div id="overview-and-advantages" class="section level2">
<h2>Overview and Advantages</h2>
<p>The Brunner-Munzel test <span class="citation">(Brunner and Munzel
2000; Neubert and Brunner 2007)</span> offers several advantages over
the Wilcoxon-Mann-Whitney tests:</p>
<ol style="list-style-type: decimal">
<li>It does not assume equal distributions (shapes) between groups</li>
<li>It is robust to heteroscedasticity (unequal variances)</li>
<li>It provides a more interpretable effect size measure (“relative
effect”)</li>
<li>It maintains good statistical properties even with unequal sample
sizes</li>
</ol>
<p>The Brunner-Munzel test is based on calculating the “stochastic
superiority” <span class="citation">(Karch 2021, i.e., probability of
superiority)</span>, which is usually referred to as the relative
effect, based on the ranks of the two groups being compared (X and Y). A
Brunner-Munzel type test is then a directional test of an effect, and
answers a question akin to “what is the probability that a randomly
sampled value of X will be greater than Y?”</p>
<p><span class="math display">\[
\hat p = P(X&gt;Y) + 0.5 \cdot P(X=Y)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(P(X&gt;Y)\)</span> is the probability
that a random value from X exceeds a random value from Y</li>
<li><span class="math inline">\(P(X=Y)\)</span> is the probability that
random values from X and Y are equal</li>
<li>The 0.5 factor means ties contribute half their weight to the
probability</li>
</ul>
<p>The relative effect <span class="math inline">\(\hat p\)</span> has
an intuitive interpretation:</p>
<ul>
<li><span class="math inline">\(\hat p = 0.5\)</span> indicates no
difference between groups</li>
<li><span class="math inline">\(\hat p &gt; 0.5\)</span> indicates
values in X tend to be greater than values in Y</li>
<li><span class="math inline">\(\hat p &lt; 0.5\)</span> indicates
values in X tend to be smaller than values in Y</li>
</ul>
</div>
<div id="basics-of-the-calculative-approach" class="section level2">
<h2>Basics of the Calculative Approach</h2>
<p>In this section, I will quickly detail the calculative approach that
underlies the Brunner-Munzel test in <code>TOSTER</code>.</p>
<p>A studentized test statistic can be calculated as:</p>
<p><span class="math display">\[
t = \sqrt{N} \cdot \frac{\hat p -p_{null}}{s}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(N\)</span> is the total sample size</li>
<li><span class="math inline">\(\hat p\)</span> is the estimated
relative effect</li>
<li><span class="math inline">\(p_{null}\)</span> is the null hypothesis
value (typically 0.5)</li>
<li><span class="math inline">\(s\)</span> is the rank-based
Brunner-Munzel standard error</li>
</ul>
<p>The default null hypothesis <span class="math inline">\(p_{null}\)</span> is typically 0.5 (50%
probability of superiority is the default null), and <span class="math inline">\(s\)</span> refers the rank-based Brunner-Munzel
standard error. The null can be modified therefore allowing for
equivalence testing <em>directly based on the relative effect</em>.
Additionally, for paired samples the probability of superiority is based
on a <em>hypothesis of exchangability</em> and is not based on the
differences scores<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</p>
<p>For more details on the calculative approach, I suggest reading <span class="citation">Karch (2021)</span>. At small sample sizes, it is
recommended that the permutation version of the test
(<code>perm = TRUE</code>) be used rather than the basic test statistic
approach.</p>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<p>The interface for the function is very similar to the
<code>t.test</code> function. The <code>brunner_munzel</code> function
itself does not allow for equivalence tests, but you can set an
alternative hypothesis for “two.sided”, “less”, or “greater”.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># studentized test</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>                      <span class="at">paired =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## Sample size in at least one group is small. Permutation test (perm = TRUE) is highly recommended.</code></pre>
<pre><code>## 
##  two-sample Brunner-Munzel test
## 
## data:  extra by group
## t = -2.1447, df = 16.898, p-value = 0.04682
## alternative hypothesis: true relative effect is not equal to 0.5
## 95 percent confidence interval:
##  0.01387048 0.49612952
## sample estimates:
## p(X&gt;Y) + .5*P(X=Y) 
##              0.255</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># permutation</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="fu">brunner_munzel</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>                      <span class="at">paired =</span> <span class="cn">FALSE</span>,</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>               <span class="at">perm =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## NOTE: Confidence intervals derived from permutation tests may differ from conclusions drawn from p-values. When discrepancies occur, consider additional diagnostics or alternative inference methods.</code></pre>
<pre><code>## 
##  two-sample Brunner-Munzel permutation test
## 
## data:  extra by group
## t-observed = -2.1447, df = 16.898, p-value = 0.0482
## alternative hypothesis: true relative effect is not equal to 0.5
## 95 percent confidence interval:
##  0.00826466 0.49593164
## sample estimates:
## p(X&gt;Y) + .5*P(X=Y) 
##              0.255</code></pre>
<p>The <code>simple_htest</code> function allows TOST tests using a
Brunner-Munzel test by setting the alternative to “equivalence” or
“minimal.effect”. The equivalence bounds, based on the relative effect,
can be set with the <code>mu</code> argument.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># permutation based Brunner-Munzel test of equivalence</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="fu">simple_htest</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>             <span class="at">test =</span> <span class="st">&quot;brunner&quot;</span>,</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>             <span class="at">data =</span> sleep,</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>             <span class="at">paired =</span> <span class="cn">FALSE</span>,</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>             <span class="at">alternative =</span> <span class="st">&quot;equ&quot;</span>,</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>             <span class="at">mu =</span> .<span class="dv">7</span>,</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>             <span class="at">perm =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## NOTE: Confidence intervals derived from permutation tests may differ from conclusions drawn from p-values. When discrepancies occur, consider additional diagnostics or alternative inference methods.
## NOTE: Confidence intervals derived from permutation tests may differ from conclusions drawn from p-values. When discrepancies occur, consider additional diagnostics or alternative inference methods.
## NOTE: Confidence intervals derived from permutation tests may differ from conclusions drawn from p-values. When discrepancies occur, consider additional diagnostics or alternative inference methods.</code></pre>
<pre><code>## 
##  two-sample Brunner-Munzel permutation test
## 
## data:  extra by group
## t-observed = -3.8954, df = 16.898, p-value = 0.9974
## alternative hypothesis: equivalence
## null values:
## relative effect relative effect 
##             0.3             0.7 
## 90 percent confidence interval:
##  0.05824864 0.45564662
## sample estimates:
## p(X&gt;Y) + .5*P(X=Y) 
##              0.255</code></pre>
<div id="interpreting-brunner-munzel-results" class="section level3">
<h3>Interpreting Brunner-Munzel Results</h3>
<p>When interpreting the Brunner-Munzel test results:</p>
<ol style="list-style-type: decimal">
<li>The relative effect (p-hat) is the primary measure of interest</li>
<li>For equivalence testing, you’re testing whether this relative effect
falls within your specified bounds</li>
<li>A significant equivalence test suggests that the probability of
superiority is statistically confined to your specified range</li>
</ol>
</div>
<div id="when-to-use-permutation" class="section level3">
<h3>When to Use Permutation</h3>
<p>The permutation approach (<code>perm = TRUE</code>) is recommended
when:</p>
<ul>
<li>Sample sizes are small (generally n &lt; 30 per group)</li>
<li>Data distributions are highly skewed or contain outliers</li>
<li>Precision is more important than computational speed</li>
</ul>
<p>Note that the permutation approach can be computationally intensive
for large datasets, potentially increasing processing time
significantly. Additionlly, with a permutation test you may observe
situations where the confidence interval and the p-values would yield
<em>different</em> conclusions.</p>
</div>
</div>
</div>
<div id="bootstrap-tost" class="section level1">
<h1>Bootstrap TOST</h1>
<p>The bootstrap is a simulation based technique, derived from
re-sampling with replacement, designed for statistical estimation and
inference. Bootstrapping techniques are very useful because they are
considered somewhat robust to the violations of assumptions for a simple
t-test. Therefore we added a bootstrap option, <code>boot_t_TOST</code>
to the package to provide another robust alternative to the
<code>t_TOST</code> function.</p>
<div id="advantages-of-bootstrapping" class="section level2">
<h2>Advantages of Bootstrapping</h2>
<p>Bootstrap methods offer several advantages for equivalence
testing:</p>
<ol style="list-style-type: decimal">
<li>They make minimal assumptions about the underlying data
distribution</li>
<li>They are robust to deviations from normality</li>
<li>They provide realistic confidence intervals even with small
samples</li>
<li>They can handle complex data structures and dependencies</li>
<li>They often provide more accurate results when parametric assumptions
are violated</li>
</ol>
<p>In this function, we provide the percentile bootstrap solution
outlined by <span class="citation">Efron and Tibshirani (1993)</span>
(see chapter 16, page 220). The bootstrapped p-values are derived from
the “studentized” version of a test of mean differences outlined by
<span class="citation">Efron and Tibshirani (1993)</span>. Overall, the
results should be similar to the results of <code>t_TOST</code>.</p>
</div>
<div id="two-sample-algorithm" class="section level2">
<h2>Two Sample Algorithm</h2>
<ol style="list-style-type: decimal">
<li><p>Form B bootstrap data sets from x* and y* wherein x* is sampled
with replacement from <span class="math inline">\(\tilde x_1,\tilde x_2,
... \tilde x_n\)</span> and y* is sampled with replacement from <span class="math inline">\(\tilde y_1,\tilde y_2, ... \tilde y_n\)</span></p>
<p>Where:</p>
<ul>
<li>B is the number of bootstrap replications (set using the
<code>R</code> parameter)</li>
<li><span class="math inline">\(\tilde x_i\)</span> and <span class="math inline">\(\tilde y_i\)</span> represent the original
observations in each group</li>
</ul></li>
<li><p>t is then evaluated on each sample, but the mean of each sample
(y or x) and the overall average (z) are subtracted from each</p></li>
</ol>
<p><span class="math display">\[
t(z^{*b}) = \frac {(\bar x^*-\bar x - \bar z) - (\bar y^*-\bar y - \bar
z)}{\sqrt {sd_y^*/n_y + sd_x^*/n_x}}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\bar x^*\)</span> and <span class="math inline">\(\bar y^*\)</span> are the means of the bootstrap
samples</li>
<li><span class="math inline">\(\bar x\)</span> and <span class="math inline">\(\bar y\)</span> are the means of the original
samples</li>
<li><span class="math inline">\(\bar z\)</span> is the overall mean</li>
<li><span class="math inline">\(sd_x^*\)</span> and <span class="math inline">\(sd_y^*\)</span> are the standard deviations of the
bootstrap samples</li>
<li><span class="math inline">\(n_x\)</span> and <span class="math inline">\(n_y\)</span> are the sample sizes</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>An approximate p-value can then be calculated as the number of
bootstrapped results greater than the observed t-statistic from the
sample.</li>
</ol>
<p><span class="math display">\[
p_{boot} = \frac {\#t(z^{*b}) \ge t_{sample}}{B}
\]</span></p>
<p>Where: - <span class="math inline">\(\#t(z^{*b}) \ge
t_{sample}\)</span> is the count of bootstrap t-statistics that exceed
the observed t-statistic - B is the total number of bootstrap
replications</p>
<p>The same process is completed for the one sample case but with the
one sample solution for the equation outlined by <span class="math inline">\(t(z^{*b})\)</span>. The paired sample case in this
bootstrap procedure is equivalent to the one sample solution because the
test is based on the difference scores.</p>
</div>
<div id="choosing-the-number-of-bootstrap-replications" class="section level2">
<h2>Choosing the Number of Bootstrap Replications</h2>
<p>When using bootstrap methods, the choice of replications (the
<code>R</code> parameter) is important:</p>
<ul>
<li><strong>R = 999 or 1999</strong>: Recommended for standard
analyses</li>
<li><strong>R = 4999 or 9999</strong>: Recommended for
publication-quality results or when precise p-values are needed</li>
<li><strong>R &lt; 500</strong>: Acceptable only for exploratory
analyses or when computational resources are limited</li>
</ul>
<p>Larger values of R provide more stable results but increase
computation time. For most purposes, 999 or 1999 replications strike a
good balance between precision and computational efficiency.</p>
</div>
<div id="example-1" class="section level2">
<h2>Example</h2>
<p>We can use the sleep data to see the bootstrapped results. Notice
that the plots show how the re-sampling via bootstrapping indicates the
instability of Hedges’s d<sub>z</sub>.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&#39;sleep&#39;</span>)</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>test1 <span class="ot">=</span> <span class="fu">boot_t_TOST</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>                      <span class="at">data =</span> sleep,</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>                      <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>                      <span class="at">eqb =</span> .<span class="dv">5</span>,</span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>                    <span class="at">R =</span> <span class="dv">499</span>)</span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a><span class="fu">print</span>(test1)</span></code></pre></div>
<pre><code>## 
## Bootstrapped Paired t-test
## 
## The equivalence test was non-significant, t(9) = -2.777, p = 1e+00
## The null hypothesis test was significant, t(9) = -4.062, p = 0e+00
## NHST: reject null significance hypothesis that the effect is equal to zero 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##                 t df p.value
## t-test     -4.062  9 &lt; 0.001
## TOST Lower -2.777  9       1
## TOST Upper -5.348  9 &lt; 0.001
## 
## Effect Sizes 
##               Estimate     SE              C.I. Conf. Level
## Raw             -1.580 0.3691 [-2.9073, -1.066]         0.9
## Hedges&#39;s g(z)   -1.174 0.7202 [-1.4089, 1.1131]         0.9
## Note: studentized bootstrap ci method utilized.</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="fu">plot</span>(test1)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<div id="interpreting-bootstrap-tost-results" class="section level3">
<h3>Interpreting Bootstrap TOST Results</h3>
<p>When interpreting the results of <code>boot_t_TOST</code>:</p>
<ol style="list-style-type: decimal">
<li>The bootstrap p-values (<code>p1</code> and <code>p2</code>)
represent the empirical probability of observing the test statistic or
more extreme values under repeated sampling</li>
<li>The confidence intervals are derived directly from the empirical
distribution of bootstrap samples</li>
<li>The distribution plots provide visual insight into the variability
of the effect size estimate</li>
</ol>
<p>For equivalence testing, examine whether both bootstrap p-values are
significant (&lt; alpha) and whether the confidence interval for the
effect size falls entirely within the equivalence bounds.</p>
</div>
</div>
</div>
<div id="ratio-of-difference-log-transformed" class="section level1">
<h1>Ratio of Difference (Log Transformed)</h1>
<p>In many bioequivalence studies, the differences between drugs are
compared on the log scale <span class="citation">(He et al.
2022)</span>. The log scale allows researchers to compare the ratio of
two means.</p>
<p><span class="math display">\[
log ( \frac{y}{x} ) = log(y) - log(x)
\]</span></p>
<p>Where: - y and x are the means of the two groups being compared - The
transformation converts multiplicative relationships into additive
ones</p>
<div id="why-use-the-natural-log-transformation" class="section level2">
<h2>Why Use The Natural Log Transformation?</h2>
<p>The <a href="https://www.fda.gov/regulatory-information/search-fda-guidance-documents/bioavailability-and-bioequivalence-studies-submitted-ndas-or-inds-general-considerations">United
States Food and Drug Administration (FDA)</a><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> has stated a rationale
for using the log transformed values:</p>
<blockquote>
<p>Using logarithmic transformation, the general linear statistical
model employed in the analysis of BE data allows inferences about the
difference between the two means on the log scale, which can then be
retransformed into inferences about the ratio of the two averages (means
or medians) on the original scale. Logarithmic transformation thus
achieves a general comparison based on the ratio rather than the
differences.</p>
</blockquote>
<p>Log transformation offers several advantages:</p>
<ol style="list-style-type: decimal">
<li>It facilitates the analysis of <strong>relative</strong> rather than
absolute differences</li>
<li>It often makes right-skewed distributions more symmetric</li>
<li>It stabilizes variance when variability increases with the mean</li>
<li>It provides an easy-to-interpret interpretable effect size (ratio of
means)</li>
</ol>
<p>In addition, the FDA considers two drugs as bioequivalent when the
ratio between x and y is less than 1.25 and greater than 0.8 (1/1.25),
which is the default equivalence bound for the log functions.</p>
</div>
<div id="applications-beyond-bioequivalence" class="section level2">
<h2>Applications Beyond Bioequivalence</h2>
<p>While log transformation is standard in bioequivalence studies, it’s
useful in many other contexts:</p>
<ul>
<li><strong>Economics</strong>: Comparing percentage changes in economic
indicators</li>
<li><strong>Environmental science</strong>: Analyzing concentration
ratios of pollutants</li>
<li><strong>Biology</strong>: Examining growth rates or concentration
ratios</li>
<li><strong>Medicine</strong>: Comparing relative efficacy of
treatments</li>
<li><strong>Psychology</strong>: Analyzing response time ratios</li>
</ul>
<p>Consider using log transformation whenever your research question is
about relative rather than absolute differences, particularly when the
data follow a multiplicative rather than additive pattern.</p>
</div>
<div id="log_tost" class="section level2">
<h2>log_TOST</h2>
<p>For example, we could compare whether the cars of different
transmissions are “equivalent” with regards to gas mileage. We can use
the default equivalence bounds (<code>eqb = 1.25</code>).</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="fu">log_TOST</span>(</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>  mpg <span class="sc">~</span> am,</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>  <span class="at">data =</span> mtcars</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## 
## Log-transformed Welch Two Sample t-test
## 
## The equivalence test was non-significant, t(23.96) = -1.363, p = 9.07e-01
## The null hypothesis test was significant, t(23.96) = -3.826, p = 8.19e-04
## NHST: reject null significance hypothesis that the effect is equal to one 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##                 t    df p.value
## t-test     -3.826 23.96 &lt; 0.001
## TOST Lower -1.363 23.96   0.907
## TOST Upper -6.288 23.96 &lt; 0.001
## 
## Effect Sizes 
##                  Estimate      SE               C.I. Conf. Level
## log(Means Ratio)  -0.3466 0.09061 [-0.5017, -0.1916]         0.9
## Means Ratio        0.7071      NA   [0.6055, 0.8256]         0.9</code></pre>
<p>Note, that the function produces t-tests similar to the
<code>t_TOST</code> function, but provides two effect sizes. The means
ratio on the log scale (the scale of the test statistics), and the means
ratio. The means ratio is missing standard error because the confidence
intervals and estimate are simply the log scale results
exponentiated.</p>
<div id="interpreting-the-means-ratio" class="section level3">
<h3>Interpreting the Means Ratio</h3>
<p>When interpreting the means ratio:</p>
<ul>
<li>A ratio of 1.0 indicates perfect equivalence (no difference)</li>
<li>Ratios &gt; 1.0 indicate that the first group has higher values than
the second</li>
<li>Ratios &lt; 1.0 indicate that the first group has lower values than
the second</li>
</ul>
<p>For equivalence testing with the default bounds (0.8, 1.25): -
Equivalence is established when the 90% confidence interval for the
ratio falls entirely within (0.8, 1.25) - This range corresponds to a
difference of ±20% on a relative scale</p>
</div>
</div>
<div id="bootstrap-log" class="section level2">
<h2>Bootstrap + Log</h2>
<p>However, it has been noted in the statistics literature that t-tests
on the logarithmic scale can be biased, and it is recommended that
bootstrapped tests be utilized instead. Therefore, the
<code>boot_log_TOST</code> function can be utilized to perform a more
precise test.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="fu">boot_log_TOST</span>(</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>  mpg <span class="sc">~</span> am,</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>  <span class="at">data =</span> mtcars,</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>  <span class="at">R =</span> <span class="dv">499</span></span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## 
## Bootstrapped Log Welch Two Sample t-test
## 
## The equivalence test was non-significant, t(23.96) = -1.363, p = 9.56e-01
## The null hypothesis test was significant, t(23.96) = -3.826, p = 0e+00
## NHST: reject null significance hypothesis that the effect is equal to 1 
## TOST: don&#39;t reject null equivalence hypothesis
## 
## TOST Results 
##                 t    df p.value
## t-test     -3.826 23.96 &lt; 0.001
## TOST Lower -1.363 23.96   0.956
## TOST Upper -6.288 23.96 &lt; 0.001
## 
## Effect Sizes 
##                  Estimate      SE               C.I. Conf. Level
## log(Means Ratio)  -0.3466 0.08722 [-0.5449, -0.1522]         0.9
## Means Ratio        0.7071 0.06209   [0.5799, 0.8588]         0.9
## Note: studentized bootstrap ci method utilized.</code></pre>
<p>The bootstrapped version is particularly recommended when:</p>
<ul>
<li>Sample sizes are small (n &lt; 30 per group)</li>
<li>Data show notable deviations from log-normality</li>
<li>You want to ensure robust confidence intervals</li>
</ul>
</div>
</div>
<div id="just-estimate-an-effect-size" class="section level1">
<h1>Just Estimate an Effect Size</h1>
<p>It was requested that a function be provided that only calculates a
robust effect size. Therefore, I created the <code>ses_calc</code> and
<code>boot_ses_calc</code> functions as robust effect size calculation<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>. The
interface is almost the same as <code>wilcox_TOST</code> but you don’t
set an equivalence bound.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="fu">ses_calc</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>         <span class="at">data =</span> sleep,</span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a>         <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a>         <span class="at">ses =</span> <span class="st">&quot;r&quot;</span>)</span></code></pre></div>
<pre><code>##                            estimate lower.ci  upper.ci conf.level
## Rank-Biserial Correlation 0.9818182 0.928369 0.9954785       0.95</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="co"># Setting bootstrap replications low to</span></span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a><span class="do">## reduce compiling time of vignette</span></span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a><span class="fu">boot_ses_calc</span>(<span class="at">formula =</span> extra <span class="sc">~</span> group,</span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>         <span class="at">data =</span> sleep,</span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a>         <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a>         <span class="at">R =</span> <span class="dv">199</span>,</span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a>         <span class="at">boot_ci =</span> <span class="st">&quot;perc&quot;</span>, <span class="co"># recommend percentile bootstrap for paired SES</span></span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a>         <span class="at">ses =</span> <span class="st">&quot;r&quot;</span>) </span></code></pre></div>
<pre><code>## Bootstrapped results contain extreme results (i.e., no overlap), caution advised interpreting the with confidence intervals.</code></pre>
<pre><code>##    estimate bias         SE  lower.ci upper.ci conf.level boot_ci
## 1 0.9818182    0 0.03743905 0.8880375        1       0.95    perc</code></pre>
<div id="choosing-between-different-bootstrap-ci-methods" class="section level2">
<h2>Choosing Between Different Bootstrap CI Methods</h2>
<p>The <code>boot_ses_calc</code> function offers several bootstrap
confidence interval methods through the <code>boot_ci</code>
parameter:</p>
<ul>
<li><strong>“perc”</strong> (Percentile): Simple and intuitive, works
well for symmetric distributions</li>
<li><strong>“basic”</strong>: Similar to percentile but adjusts for
bias, more conservative</li>
<li><strong>“norm”</strong> (Normal approximation): Assumes normality of
the bootstrap distribution</li>
</ul>
</div>
</div>
<div id="summary-comparison-of-robust-tost-methods" class="section level1">
<h1>Summary Comparison of Robust TOST Methods</h1>
<table>
<colgroup>
<col width="15%" />
<col width="29%" />
<col width="25%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Key Advantages</th>
<th>Limitations</th>
<th>Best Use Cases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Wilcoxon TOST</strong></td>
<td>Simple, widely accepted, minimal assumptions</td>
<td>Less power than parametric tests with normal data</td>
<td>Ordinal data, non-normal distributions, presence of outliers</td>
</tr>
<tr class="even">
<td><strong>Brunner-Munzel</strong></td>
<td>Robust to unequal distributions, interpretable effect</td>
<td>Computationally intensive with permutation</td>
<td>Different distribution shapes between groups,
heteroscedasticity</td>
</tr>
<tr class="odd">
<td><strong>Bootstrap TOST</strong></td>
<td>Flexible, minimal assumptions, works with small samples</td>
<td>Computationally intensive, results vary slightly between runs</td>
<td>Small samples, complex data structures, when precise CIs are
important</td>
</tr>
<tr class="even">
<td><strong>Log-Transformed</strong></td>
<td>Focuses on relative differences, often stabilizes variance</td>
<td>Requires positive data, can be biased with small samples</td>
<td>Bioequivalence studies, comparing ratios rather than absolute
differences</td>
</tr>
</tbody>
</table>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>The robust TOST procedures provided in the TOSTER package offer
reliable alternatives to standard parametric equivalence testing when
data violate typical assumptions. By selecting the appropriate robust
method for your specific data characteristics and research question, you
can ensure more valid statistical inferences about equivalence or
minimal effects.</p>
<p>Remember that no single method is universally superior - the choice
depends on your data structure, sample size, and specific research
question. When in doubt, running multiple approaches and comparing
results can provide valuable insights into the robustness of your
conclusions.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-agresti" class="csl-entry">
Agresti, Alan. 1980. <span>“Generalized Odds Ratios for Ordinal
Data.”</span> <em>Biometrics</em>, 59–67. <a href="https://doi.org/10.2307/2530495">https://doi.org/10.2307/2530495</a>.
</div>
<div id="ref-brunner2000" class="csl-entry">
Brunner, Edgar, and Ullrich Munzel. 2000. <span>“The Nonparametric
Behrens-Fisher Problem: Asymptotic Theory and a Small-Sample
Approximation.”</span> <em>Biometrical Journal</em> 42 (1): 17–25. <a href="https://doi.org/10.1002/(sici)1521-4036(200001)42:1&lt;17::aid-bimj17&gt;3.0.co;2-u">https://doi.org/10.1002/(sici)1521-4036(200001)42:1&lt;17::aid-bimj17&gt;3.0.co;2-u</a>.
</div>
<div id="ref-efron93" class="csl-entry">
Efron, Bradley, and Robert J. Tibshirani. 1993. <em>An Introduction to
the Bootstrap</em>. Monographs on Statistics and Applied Probability 57.
Boca Raton, Florida, USA: Chapman &amp; Hall/CRC.
</div>
<div id="ref-he2022" class="csl-entry">
He, Y, Y Deng, C You, and X H Zhou. 2022. <span>“Equivalence Tests for
Ratio of Means in Bioequivalence Studies Under Crossover
Designs.”</span> <em>Statistical Methods in Medical Research</em>,
09622802221093721. <a href="https://doi.org/10.1177/09622802221093721">https://doi.org/10.1177/09622802221093721</a>.
</div>
<div id="ref-karch2021" class="csl-entry">
Karch, Julian D. 2021. <span>“Psychologists Should Use Brunner-Munzel’s
Instead of Mann-Whitney’s Test as the Default Nonparametric
Procedure.”</span> <em>Advances in Methods and Practices in
Psychological Science</em> 4 (2): 251524592199960. <a href="https://doi.org/10.1177/2515245921999602">https://doi.org/10.1177/2515245921999602</a>.
</div>
<div id="ref-Kerby_2014" class="csl-entry">
Kerby, Dave S. 2014. <span>“The Simple Difference Formula: An Approach
to Teaching Nonparametric Correlation.”</span> <em>Comprehensive
Psychology</em> 3 (January): 11.IT.3.1. <a href="https://doi.org/10.2466/11.it.3.1">https://doi.org/10.2466/11.it.3.1</a>.
</div>
<div id="ref-neubert2007" class="csl-entry">
Neubert, Karin, and Edgar Brunner. 2007. <span>“A Studentized
Permutation Test for the Non-Parametric Behrens<span></span>fisher
Problem.”</span> <em>Computational Statistics and Data Analysis</em> 51
(10): 5192–5204. <a href="https://doi.org/10.1016/j.csda.2006.05.024">https://doi.org/10.1016/j.csda.2006.05.024</a>.
</div>
<div id="ref-wmwodds" class="csl-entry">
O’Brien, Ralph G, and John Castelloe. 2006. <span>“Exploiting the Link
Between the Wilcoxon-Mann-Whitney Test and a Simple Odds
Statistic,”</span> 209–31.
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Directly inspired by this blog post from Professor Frank
Harrell <a href="https://hbiostat.org/blog/post/wpo/" class="uri">https://hbiostat.org/blog/post/wpo/</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>I would like to note that I think the statistical
properties of the WMW tests are sound, and Frank Harrell has written <a href="https://www.fharrell.com/post/po/">many</a> <a href="https://www.fharrell.com/post/wpo/">blogposts</a> outlined their
sound application in biomedicine. <a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>This means the relative effect will <em>not</em> match
the concordance probability provided by <code>ses_calc</code><a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Food and Drug Administration (2014). Bioavailability and
Bioequivalence Studies Submitted in NDAs or INDs — General
Considerations.Center for Drug Evaluation and Research. Docket:
FDA-2014-D-0204<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>The results differ greatly because the bootstrap CI
method, basic bootstrap, is more conservative than the parametric
method. This difference is more apparent with extremely small samples
like that in the <code>sleep</code> dataset.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
